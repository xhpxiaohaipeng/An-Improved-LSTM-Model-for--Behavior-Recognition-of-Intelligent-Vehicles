{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "def labeltoint(label):\n",
    "    if label == 'left':\n",
    "        label = 0\n",
    "    if label == 'keep':\n",
    "        label = 1\n",
    "    if label == 'right':\n",
    "        label = 2\n",
    "    return label\n",
    "\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('data1/train.json', 'r') as f:\n",
    "    j = json.load(f)\n",
    "  #  print(j.keys())\n",
    "    X_train = j['states']\n",
    "    Y_train = j['labels']\n",
    "    for i in range(len(Y_train)):\n",
    "        Y_train[i] = labeltoint(Y_train[i])\n",
    "  #  print(Y_train)\n",
    "\n",
    "with open('data1/test.json', 'r') as f:\n",
    "    j = json.load(f)\n",
    "    X_test = j['states']\n",
    "    Y_test = j['labels']\n",
    "    for i in range(len(Y_test)):\n",
    "        Y_test[i] = labeltoint(Y_test[i])\n",
    "\n",
    "split_frac = 0.8\n",
    "X_train, Y_train, X_test, Y_test = np.array(X_train).astype(np.float32), np.array(Y_train).astype(np.long), np.array(\n",
    "    X_test).astype(np.float32), np.array(Y_test).astype(np.long)\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "val_x, test_x = X_test[:len(X_test) // 2], X_test[len(X_test) // 2:]\n",
    "val_y, test_y = Y_test[:len(Y_test) // 2], Y_test[len(Y_test) // 2:]\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy((X_train)), torch.from_numpy(Y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers,dropout=0, batch_first=True)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim,hidden_dim*2)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        self.fc2 = nn.Linear(X_train.shape[1],output_size)\n",
    "       # self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x, hidden):\n",
    "        # x (batch_size, seq_length, input_size)\n",
    "        # hidden (n_layers, batch_size, hidden_dim)\n",
    "        # r_out (batch_size, time_step, hidden_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.lstm(x, hidden)\n",
    "        \"\"\"\n",
    "        r_out = torch.mean(r_out,dim=2).squeeze()\n",
    "        \n",
    "        output= self.fc2(r_out)\n",
    "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
    "        \"\"\"\n",
    "        r_out = r_out.contiguous().view(-1, self.hidden_dim)  \n",
    "        \n",
    "        # get final output \n",
    "        output = self.fc1(r_out)\n",
    "        output = self.fc(output)\n",
    "        output = output.view(batch_size,-1,3)\n",
    "        output = output[:,-1]\n",
    "       # output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_on_gpu = True\n",
    "else:\n",
    "    train_on_gpu = False\n",
    "\n",
    "\n",
    "# In[8]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,epochs,train_loader,valid_loader,clip,lr = 0.0002):\n",
    "    # train for some number of epochs\n",
    "    # loss and optimization functions\n",
    "\n",
    "    loss_min = np.inf\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    counter = 0\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    accuracies_e = []\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        net.train()\n",
    "        # batch loop\n",
    "        train_loss = []\n",
    "        for inputs, labels in train_loader:\n",
    "            h = net.init_hidden(inputs.shape[0])\n",
    "            h = tuple([each.data for each in h])\n",
    "            inputs = inputs.unsqueeze(2)\n",
    "            if (train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            # get the output from the model\n",
    "            # print(inputs)\n",
    "            output, h = net(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "          #  print(output.shape,labels.shape)\n",
    "           # print(output[:1])\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            # loss stats\n",
    "                # Get validation loss\n",
    "\n",
    "        val_losses = []\n",
    "        net.eval()\n",
    "        accuracies = []\n",
    "        for inputs, labels in valid_loader:\n",
    "            val_h = net.init_hidden(inputs.shape[0])\n",
    "            inputs = inputs.unsqueeze(2)\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                   # val_h = tuple([each.data for each in val_h])\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "            if (train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            output, val_h = net(inputs, val_h)\n",
    "\n",
    "            val_loss = criterion(output, labels)\n",
    "            _, class_ = torch.max(output, dim=1)\n",
    "            equal = class_ == labels.view(class_.shape)\n",
    "            accuracy = torch.mean(equal.type(torch.FloatTensor)).item()\n",
    "            val_losses.append(val_loss.item())\n",
    "            accuracies.append(accuracy)\n",
    "                \n",
    "\n",
    "        net.train()\n",
    "        losses_train.append(np.mean(train_loss))\n",
    "        losses_valid.append(np.mean(val_losses))\n",
    "        accuracies_e.append(np.mean(np.mean(accuracies)))\n",
    "        print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "                      \"Loss: {}...\".format(np.mean(train_loss)),\n",
    "                      \"Val Loss: {}...\".format(np.mean(val_losses)),\n",
    "                      \"val accuracy:{}.\".format(np.mean(accuracies))\n",
    "                     )\n",
    "        if np.mean(val_losses) < loss_min:\n",
    "            print('Val loss decreased...')\n",
    "            torch.save(net.state_dict(),'model/lstm_behavior_prediction_old.pt')\n",
    "            loss_min = np.mean(val_losses)\n",
    "    print('min loss',loss_min)\n",
    "   # plt.plot(losses_train,color='r',label='train_loss')\n",
    "    #plt.plot(losses_valid,color='g',label='valid_loss')\n",
    "    plt.plot(losses_train,color='r',label='训练损失')\n",
    "    plt.plot(losses_valid,color='g',label='验证损失')\n",
    "    #plt.title('Loss_Trend')\n",
    "    #plt.xlabel('Epoches')\n",
    "    #plt.ylabel('Loss')\n",
    "    plt.title('损失变化')\n",
    "    plt.xlabel('迭代次数')\n",
    "    plt.ylabel('损失大小')\n",
    "    plt.legend()\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.savefig('behavior_image/loss_lstm_behavior_old1.svg',dpi=300)\n",
    "    plt.savefig('behavior_image/loss_lstm_behavior_old1.png',dpi=300)\n",
    "    \n",
    "    return accuracies_e\n",
    "                            \n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "\n",
    "def test(net,test_loader):\n",
    "    # Get test data loss and accuracy\n",
    "    lr = 0.001\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_losses = []  # track loss\n",
    "    accuracies = []\n",
    "    net.eval()\n",
    "    # iterate over test data\n",
    "    class_correct = np.zeros(3)\n",
    "    class_total = np.zeros(3)\n",
    "    classes = ['left','keep','right']\n",
    "    for inputs, y in test_loader:\n",
    "        h = net.init_hidden(inputs.shape[0])\n",
    "        inputs = inputs.unsqueeze(2)\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            inputs, y = inputs.cuda(), y.cuda()\n",
    "        # get predicted outputs\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate loss\n",
    "        test_loss = criterion(output, y)\n",
    "        _, class_ = torch.max(output, dim=1)\n",
    "        equal = class_ == y.view(class_.shape)\n",
    "        for i in range(y.shape[0]):\n",
    "            label = y.data[i].item()\n",
    "            class_correct[label] += equal[i].item()\n",
    "            class_total[label] += 1\n",
    "        accuracy = torch.mean(equal.type(torch.FloatTensor)).item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # -- stats! -- ##\n",
    "    # avg test loss\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "    for i in range(3):\n",
    "        if class_total[i]>0:\n",
    "            print('Test Accuracy of {}:{:.4f}({}/{})'.format(classes[i],100*class_correct[i]/class_total[i],\n",
    "                 int(np.sum(class_correct[i])),\n",
    "                 int(np.sum(class_total[i]))))\n",
    "        else:\n",
    "            print('Test Accuracy of {}:N/A(no examples)'.format(classes[i]))\n",
    "    print('Test Accuracy(Overall):{:.4f} ({}/{})'.format(100*np.sum(class_correct)/np.sum(class_total),\n",
    "                                                    int(np.sum(class_correct)),\n",
    "                                                    int(np.sum(class_total))))\n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_losses)),'Test Accuracy:{}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/350... Loss: 1.0916933019955952... Val Loss: 1.0916500091552734... val accuracy:0.40061475336551666.\n",
      "Val loss decreased...\n",
      "Epoch: 2/350... Loss: 1.081933319568634... Val Loss: 1.092461884021759... val accuracy:0.4002305269241333.\n",
      "Epoch: 3/350... Loss: 1.0798627038796742... Val Loss: 1.0805219411849976... val accuracy:0.39984631538391113.\n",
      "Val loss decreased...\n",
      "Epoch: 4/350... Loss: 1.0617770155270894... Val Loss: 1.0392597913742065... val accuracy:0.39984631538391113.\n",
      "Val loss decreased...\n",
      "Epoch: 5/350... Loss: 0.9573570340871811... Val Loss: 0.7769854664802551... val accuracy:0.725537896156311.\n",
      "Val loss decreased...\n",
      "Epoch: 6/350... Loss: 0.6636927425861359... Val Loss: 0.5003583282232285... val accuracy:0.8090420067310333.\n",
      "Val loss decreased...\n",
      "Epoch: 7/350... Loss: 0.47365788122018176... Val Loss: 0.343133881688118... val accuracy:0.8965163826942444.\n",
      "Val loss decreased...\n",
      "Epoch: 8/350... Loss: 0.4541744391123454... Val Loss: 0.40445439517498016... val accuracy:0.8477202951908112.\n",
      "Epoch: 9/350... Loss: 0.44587354610363644... Val Loss: 0.288682758808136... val accuracy:0.8957479596138.\n",
      "Val loss decreased...\n",
      "Epoch: 10/350... Loss: 0.3644513587156932... Val Loss: 0.2777847796678543... val accuracy:0.8726946711540222.\n",
      "Val loss decreased...\n",
      "Epoch: 11/350... Loss: 0.33801544457674026... Val Loss: 0.24468497931957245... val accuracy:0.8719262182712555.\n",
      "Val loss decreased...\n",
      "Epoch: 12/350... Loss: 0.2973661820093791... Val Loss: 0.253218837082386... val accuracy:0.8945952951908112.\n",
      "Epoch: 13/350... Loss: 0.2815438409646352... Val Loss: 0.20022931694984436... val accuracy:0.9043288826942444.\n",
      "Val loss decreased...\n",
      "Epoch: 14/350... Loss: 0.27979283407330513... Val Loss: 0.224549762904644... val accuracy:0.9203381240367889.\n",
      "Epoch: 15/350... Loss: 0.269306518137455... Val Loss: 0.2003912776708603... val accuracy:0.8867827951908112.\n",
      "Epoch: 16/350... Loss: 0.28713086744149524... Val Loss: 0.20297084748744965... val accuracy:0.9031762182712555.\n",
      "Epoch: 17/350... Loss: 0.2512917307515939... Val Loss: 0.20546309649944305... val accuracy:0.8812756240367889.\n",
      "Epoch: 18/350... Loss: 0.24740204215049744... Val Loss: 0.18343652039766312... val accuracy:0.9445440471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 19/350... Loss: 0.2597811035811901... Val Loss: 0.16849540174007416... val accuracy:0.9214907884597778.\n",
      "Val loss decreased...\n",
      "Epoch: 20/350... Loss: 0.262473925948143... Val Loss: 0.2667268067598343... val accuracy:0.8793545067310333.\n",
      "Epoch: 21/350... Loss: 0.24693364650011063... Val Loss: 0.1793995127081871... val accuracy:0.9430071711540222.\n",
      "Epoch: 22/350... Loss: 0.23061678310235342... Val Loss: 0.16813453286886215... val accuracy:0.9437756240367889.\n",
      "Val loss decreased...\n",
      "Epoch: 23/350... Loss: 0.22775976111491522... Val Loss: 0.16046855598688126... val accuracy:0.9445440471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 24/350... Loss: 0.24059887044131756... Val Loss: 0.15940261632204056... val accuracy:0.9515881240367889.\n",
      "Val loss decreased...\n",
      "Epoch: 25/350... Loss: 0.24058529486258826... Val Loss: 0.1934136152267456... val accuracy:0.8961321711540222.\n",
      "Epoch: 26/350... Loss: 0.24649644767244658... Val Loss: 0.1887737661600113... val accuracy:0.9113729596138.\n",
      "Epoch: 27/350... Loss: 0.22316118205587068... Val Loss: 0.16998940706253052... val accuracy:0.9039446711540222.\n",
      "Epoch: 28/350... Loss: 0.23100768153866133... Val Loss: 0.27084989100694656... val accuracy:0.8949795067310333.\n",
      "Epoch: 29/350... Loss: 0.26739810158809024... Val Loss: 0.21150923520326614... val accuracy:0.8957479596138.\n",
      "Epoch: 30/350... Loss: 0.28774111345410347... Val Loss: 0.2294677495956421... val accuracy:0.8863985538482666.\n",
      "Epoch: 31/350... Loss: 0.2633880140880744... Val Loss: 0.16637173295021057... val accuracy:0.9433913826942444.\n",
      "Epoch: 32/350... Loss: 0.22265891234079996... Val Loss: 0.17271537333726883... val accuracy:0.9363473355770111.\n",
      "Epoch: 33/350... Loss: 0.20868248616655669... Val Loss: 0.16185498982667923... val accuracy:0.9437756240367889.\n",
      "Epoch: 34/350... Loss: 0.19872402648131052... Val Loss: 0.20974694192409515... val accuracy:0.9113729596138.\n",
      "Epoch: 35/350... Loss: 0.21613871306180954... Val Loss: 0.1675787940621376... val accuracy:0.9106045067310333.\n",
      "Epoch: 36/350... Loss: 0.18685084829727808... Val Loss: 0.15556740760803223... val accuracy:0.9281506240367889.\n",
      "Val loss decreased...\n",
      "Epoch: 37/350... Loss: 0.19099274898568788... Val Loss: 0.13982553035020828... val accuracy:0.9519723355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 38/350... Loss: 0.18383698351681232... Val Loss: 0.17218351364135742... val accuracy:0.9043288826942444.\n",
      "Epoch: 39/350... Loss: 0.20737108712395033... Val Loss: 0.17416536062955856... val accuracy:0.9285348355770111.\n",
      "Epoch: 40/350... Loss: 0.17922039764622846... Val Loss: 0.1369950771331787... val accuracy:0.9515881240367889.\n",
      "Val loss decreased...\n",
      "Epoch: 41/350... Loss: 0.179068257411321... Val Loss: 0.21635447442531586... val accuracy:0.8969006240367889.\n",
      "Epoch: 42/350... Loss: 0.1724231199671825... Val Loss: 0.1293170526623726... val accuracy:0.9367315471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 43/350... Loss: 0.16816295497119427... Val Loss: 0.21591224521398544... val accuracy:0.9125256240367889.\n",
      "Epoch: 44/350... Loss: 0.21869666688144207... Val Loss: 0.1612880527973175... val accuracy:0.9211065471172333.\n",
      "Epoch: 45/350... Loss: 0.1868086395164331... Val Loss: 0.14872367680072784... val accuracy:0.9195696711540222.\n",
      "Epoch: 46/350... Loss: 0.16218380505839983... Val Loss: 0.13830611482262611... val accuracy:0.9527407884597778.\n",
      "Epoch: 47/350... Loss: 0.18177032408614954... Val Loss: 0.15216513723134995... val accuracy:0.9277663826942444.\n",
      "Epoch: 48/350... Loss: 0.16652748516450325... Val Loss: 0.1403484120965004... val accuracy:0.9363473355770111.\n",
      "Epoch: 49/350... Loss: 0.1715984089920918... Val Loss: 0.14235375821590424... val accuracy:0.9515881240367889.\n",
      "Epoch: 50/350... Loss: 0.17287618853151798... Val Loss: 0.1843174695968628... val accuracy:0.9199538826942444.\n",
      "Epoch: 51/350... Loss: 0.15884853837390742... Val Loss: 0.15731500089168549... val accuracy:0.9273821711540222.\n",
      "Epoch: 52/350... Loss: 0.17379161963860193... Val Loss: 0.11542073637247086... val accuracy:0.9683657884597778.\n",
      "Val loss decreased...\n",
      "Epoch: 53/350... Loss: 0.1760168398420016... Val Loss: 0.12718584388494492... val accuracy:0.9363473355770111.\n",
      "Epoch: 54/350... Loss: 0.16555674063662687... Val Loss: 0.12595365941524506... val accuracy:0.9433913826942444.\n",
      "Epoch: 55/350... Loss: 0.1637271208067735... Val Loss: 0.12055203691124916... val accuracy:0.9679815471172333.\n",
      "Epoch: 56/350... Loss: 0.14695277499655882... Val Loss: 0.17645840346813202... val accuracy:0.9043288826942444.\n",
      "Epoch: 57/350... Loss: 0.17064721075197062... Val Loss: 0.16324060782790184... val accuracy:0.9191854596138.\n",
      "Epoch: 58/350... Loss: 0.15884886185328165... Val Loss: 0.11917100846767426... val accuracy:0.9679815471172333.\n",
      "Epoch: 59/350... Loss: 0.13704214058816433... Val Loss: 0.1193985752761364... val accuracy:0.9597848355770111.\n",
      "Epoch: 60/350... Loss: 0.1343426269789537... Val Loss: 0.12332116812467575... val accuracy:0.9441598355770111.\n",
      "Epoch: 61/350... Loss: 0.13943223965664706... Val Loss: 0.11142273619771004... val accuracy:0.9675973355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 62/350... Loss: 0.14895228824267784... Val Loss: 0.12317472323775291... val accuracy:0.9601690471172333.\n",
      "Epoch: 63/350... Loss: 0.12616239612301192... Val Loss: 0.11866999790072441... val accuracy:0.9441598355770111.\n",
      "Epoch: 64/350... Loss: 0.12970721659561... Val Loss: 0.1459413841366768... val accuracy:0.9437756240367889.\n",
      "Epoch: 65/350... Loss: 0.1315614723910888... Val Loss: 0.11422955989837646... val accuracy:0.9527407884597778.\n",
      "Epoch: 66/350... Loss: 0.12812722163895765... Val Loss: 0.14583672024309635... val accuracy:0.9375.\n",
      "Epoch: 67/350... Loss: 0.14985377915824452... Val Loss: 0.11400391161441803... val accuracy:0.9601690471172333.\n",
      "Epoch: 68/350... Loss: 0.1590101302911838... Val Loss: 0.11397441476583481... val accuracy:0.9367315471172333.\n",
      "Epoch: 69/350... Loss: 0.141156621898214... Val Loss: 0.1337566152215004... val accuracy:0.9519723355770111.\n",
      "Epoch: 70/350... Loss: 0.1313441333671411... Val Loss: 0.12097149714827538... val accuracy:0.9523565471172333.\n",
      "Epoch: 71/350... Loss: 0.13219875004142523... Val Loss: 0.12872286513447762... val accuracy:0.9359631240367889.\n",
      "Epoch: 72/350... Loss: 0.13713223300874233... Val Loss: 0.11958807334303856... val accuracy:0.9355788826942444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/350... Loss: 0.12825391193230948... Val Loss: 0.14466533064842224... val accuracy:0.9281506240367889.\n",
      "Epoch: 74/350... Loss: 0.12573093362152576... Val Loss: 0.10843980684876442... val accuracy:0.9519723355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 75/350... Loss: 0.12771902357538542... Val Loss: 0.10721273720264435... val accuracy:0.9515881240367889.\n",
      "Val loss decreased...\n",
      "Epoch: 76/350... Loss: 0.13330887630581856... Val Loss: 0.13676592707633972... val accuracy:0.9359631240367889.\n",
      "Epoch: 77/350... Loss: 0.12218144970635574... Val Loss: 0.1478252410888672... val accuracy:0.9367315471172333.\n",
      "Epoch: 78/350... Loss: 0.141439076513052... Val Loss: 0.13983343169093132... val accuracy:0.9281506240367889.\n",
      "Epoch: 79/350... Loss: 0.16122165167083344... Val Loss: 0.10566635802388191... val accuracy:0.9683657884597778.\n",
      "Val loss decreased...\n",
      "Epoch: 80/350... Loss: 0.13640461520602307... Val Loss: 0.13913525640964508... val accuracy:0.9277663826942444.\n",
      "Epoch: 81/350... Loss: 0.14089330720404783... Val Loss: 0.10277452319860458... val accuracy:0.9519723355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 82/350... Loss: 0.12637134765585264... Val Loss: 0.1481800675392151... val accuracy:0.9367315471172333.\n",
      "Epoch: 83/350... Loss: 0.15499753567079702... Val Loss: 0.12724877893924713... val accuracy:0.9597848355770111.\n",
      "Epoch: 84/350... Loss: 0.2743206008647879... Val Loss: 0.25421106070280075... val accuracy:0.9109887182712555.\n",
      "Epoch: 85/350... Loss: 0.1756573673337698... Val Loss: 0.12573754414916039... val accuracy:0.9441598355770111.\n",
      "Epoch: 86/350... Loss: 0.12520548359801373... Val Loss: 0.11649130657315254... val accuracy:0.9601690471172333.\n",
      "Epoch: 87/350... Loss: 0.10823204244176547... Val Loss: 0.1031930223107338... val accuracy:0.9679815471172333.\n",
      "Epoch: 88/350... Loss: 0.11235793121159077... Val Loss: 0.1135768536478281... val accuracy:0.9512038826942444.\n",
      "Epoch: 89/350... Loss: 0.13818420687069496... Val Loss: 0.10967778414487839... val accuracy:0.9449282884597778.\n",
      "Epoch: 90/350... Loss: 0.11782321333885193... Val Loss: 0.09924471750855446... val accuracy:0.9675973355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 91/350... Loss: 0.1125292560706536... Val Loss: 0.09849154576659203... val accuracy:0.9679815471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 92/350... Loss: 0.11849546805024147... Val Loss: 0.1132107563316822... val accuracy:0.9519723355770111.\n",
      "Epoch: 93/350... Loss: 0.1418090257793665... Val Loss: 0.09277990087866783... val accuracy:0.9679815471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 94/350... Loss: 0.17086633139600357... Val Loss: 0.12141698878258467... val accuracy:0.953125.\n",
      "Epoch: 95/350... Loss: 0.13700825658937296... Val Loss: 0.13869982585310936... val accuracy:0.9277663826942444.\n",
      "Epoch: 96/350... Loss: 0.12653098503748575... Val Loss: 0.17988046258687973... val accuracy:0.9039446711540222.\n",
      "Epoch: 97/350... Loss: 0.14506889010469118... Val Loss: 0.16032784432172775... val accuracy:0.9117571711540222.\n",
      "Epoch: 98/350... Loss: 0.12014205132921536... Val Loss: 0.10160945728421211... val accuracy:0.9597848355770111.\n",
      "Epoch: 99/350... Loss: 0.12086683077116807... Val Loss: 0.16114404052495956... val accuracy:0.9203381240367889.\n",
      "Epoch: 100/350... Loss: 0.14247832323114076... Val Loss: 0.20246397703886032... val accuracy:0.9043288826942444.\n",
      "Epoch: 101/350... Loss: 0.12790213959912458... Val Loss: 0.09112254530191422... val accuracy:0.9757940471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 102/350... Loss: 0.11309490446001291... Val Loss: 0.09827369451522827... val accuracy:0.9683657884597778.\n",
      "Epoch: 103/350... Loss: 0.12307869115223487... Val Loss: 0.160556361079216... val accuracy:0.9266137182712555.\n",
      "Epoch: 104/350... Loss: 0.14549600953857103... Val Loss: 0.16634551435709... val accuracy:0.9281506240367889.\n",
      "Epoch: 105/350... Loss: 0.13385676809897026... Val Loss: 0.17240474373102188... val accuracy:0.9199538826942444.\n",
      "Epoch: 106/350... Loss: 0.12609538435935974... Val Loss: 0.10655678063631058... val accuracy:0.9597848355770111.\n",
      "Epoch: 107/350... Loss: 0.10979273139188687... Val Loss: 0.09733125008642673... val accuracy:0.9605532884597778.\n",
      "Epoch: 108/350... Loss: 0.10837289939324062... Val Loss: 0.0949157290160656... val accuracy:0.9594006240367889.\n",
      "Epoch: 109/350... Loss: 0.10763163616259892... Val Loss: 0.09302549809217453... val accuracy:0.9754098355770111.\n",
      "Epoch: 110/350... Loss: 0.1179417163754503... Val Loss: 0.10939132049679756... val accuracy:0.9523565471172333.\n",
      "Epoch: 111/350... Loss: 0.1199042370232443... Val Loss: 0.15780436992645264... val accuracy:0.9273821711540222.\n",
      "Epoch: 112/350... Loss: 0.11574484718342622... Val Loss: 0.15378836542367935... val accuracy:0.9211065471172333.\n",
      "Epoch: 113/350... Loss: 0.13634006461749473... Val Loss: 0.08693668432533741... val accuracy:0.9761782884597778.\n",
      "Val loss decreased...\n",
      "Epoch: 114/350... Loss: 0.11826585605740547... Val Loss: 0.10034050792455673... val accuracy:0.9597848355770111.\n",
      "Epoch: 115/350... Loss: 0.10490566305816174... Val Loss: 0.08768721669912338... val accuracy:0.9683657884597778.\n",
      "Epoch: 116/350... Loss: 0.10177373203138511... Val Loss: 0.1201053261756897... val accuracy:0.9359631240367889.\n",
      "Epoch: 117/350... Loss: 0.11911353996644418... Val Loss: 0.08835848979651928... val accuracy:0.96875.\n",
      "Epoch: 118/350... Loss: 0.10444984150429566... Val Loss: 0.10846177116036415... val accuracy:0.9523565471172333.\n",
      "Epoch: 119/350... Loss: 0.10627245406309764... Val Loss: 0.09126481786370277... val accuracy:0.9515881240367889.\n",
      "Epoch: 120/350... Loss: 0.09738259141643842... Val Loss: 0.10644940845668316... val accuracy:0.9597848355770111.\n",
      "Epoch: 121/350... Loss: 0.13428512370834747... Val Loss: 0.09120070189237595... val accuracy:0.9515881240367889.\n",
      "Epoch: 122/350... Loss: 0.12092914121846358... Val Loss: 0.12933404743671417... val accuracy:0.9195696711540222.\n",
      "Epoch: 123/350... Loss: 0.10746051433185737... Val Loss: 0.11324271000921726... val accuracy:0.9605532884597778.\n",
      "Epoch: 124/350... Loss: 0.1040662092467149... Val Loss: 0.1131272092461586... val accuracy:0.9515881240367889.\n",
      "Epoch: 125/350... Loss: 0.10504340473562479... Val Loss: 0.08482173085212708... val accuracy:0.9683657884597778.\n",
      "Val loss decreased...\n",
      "Epoch: 126/350... Loss: 0.09058400817836325... Val Loss: 0.09960677847266197... val accuracy:0.9515881240367889.\n",
      "Epoch: 127/350... Loss: 0.14589739870280027... Val Loss: 0.09435959905385971... val accuracy:0.9437756240367889.\n",
      "Epoch: 128/350... Loss: 0.14804497205962738... Val Loss: 0.09929313883185387... val accuracy:0.9594006240367889.\n",
      "Epoch: 129/350... Loss: 0.11360951419919729... Val Loss: 0.09777223691344261... val accuracy:0.9519723355770111.\n",
      "Epoch: 130/350... Loss: 0.1045311763882637... Val Loss: 0.09856973960995674... val accuracy:0.9523565471172333.\n",
      "Epoch: 131/350... Loss: 0.11593754403293133... Val Loss: 0.12379277497529984... val accuracy:0.9445440471172333.\n",
      "Epoch: 132/350... Loss: 0.10752764344215393... Val Loss: 0.08564681001007557... val accuracy:0.9605532884597778.\n",
      "Epoch: 133/350... Loss: 0.11893512789780895... Val Loss: 0.11458821967244148... val accuracy:0.9203381240367889.\n",
      "Epoch: 134/350... Loss: 0.13234166304270426... Val Loss: 0.12844376266002655... val accuracy:0.9359631240367889.\n",
      "Epoch: 135/350... Loss: 0.105000385393699... Val Loss: 0.10704030841588974... val accuracy:0.9441598355770111.\n",
      "Epoch: 136/350... Loss: 0.09156931191682816... Val Loss: 0.09305882453918457... val accuracy:0.9675973355770111.\n",
      "Epoch: 137/350... Loss: 0.09559179469943047... Val Loss: 0.11713698878884315... val accuracy:0.9363473355770111.\n",
      "Epoch: 138/350... Loss: 0.09437586863835652... Val Loss: 0.0903291329741478... val accuracy:0.9605532884597778.\n",
      "Epoch: 139/350... Loss: 0.1037783301435411... Val Loss: 0.10906278342008591... val accuracy:0.9519723355770111.\n",
      "Epoch: 140/350... Loss: 0.10815291106700897... Val Loss: 0.08590544760227203... val accuracy:0.9675973355770111.\n",
      "Epoch: 141/350... Loss: 0.09713597781956196... Val Loss: 0.08246497064828873... val accuracy:0.9679815471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 142/350... Loss: 0.08263236346344154... Val Loss: 0.08698844909667969... val accuracy:0.9601690471172333.\n",
      "Epoch: 143/350... Loss: 0.09350727420921127... Val Loss: 0.09134263545274734... val accuracy:0.9523565471172333.\n",
      "Epoch: 144/350... Loss: 0.09231027526160081... Val Loss: 0.0881456658244133... val accuracy:0.9597848355770111.\n",
      "Epoch: 145/350... Loss: 0.08413802584012349... Val Loss: 0.08169496431946754... val accuracy:0.9519723355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 146/350... Loss: 0.082554891705513... Val Loss: 0.09441659227013588... val accuracy:0.9597848355770111.\n",
      "Epoch: 147/350... Loss: 0.0961513154519101... Val Loss: 0.09171707183122635... val accuracy:0.9597848355770111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148/350... Loss: 0.12476272943119208... Val Loss: 0.10887143388390541... val accuracy:0.953125.\n",
      "Epoch: 149/350... Loss: 0.09614271049698193... Val Loss: 0.10721300169825554... val accuracy:0.9605532884597778.\n",
      "Epoch: 150/350... Loss: 0.12156717758625746... Val Loss: 0.0931830182671547... val accuracy:0.9527407884597778.\n",
      "Epoch: 151/350... Loss: 0.10879049077630043... Val Loss: 0.1130204051733017... val accuracy:0.9601690471172333.\n",
      "Epoch: 152/350... Loss: 0.08557000445822875... Val Loss: 0.08761914819478989... val accuracy:0.9441598355770111.\n",
      "Epoch: 153/350... Loss: 0.09082819614559412... Val Loss: 0.08508878946304321... val accuracy:0.9594006240367889.\n",
      "Epoch: 154/350... Loss: 0.08452081307768822... Val Loss: 0.09100637398660183... val accuracy:0.9594006240367889.\n",
      "Epoch: 155/350... Loss: 0.08233634041001399... Val Loss: 0.10892854258418083... val accuracy:0.9601690471172333.\n",
      "Epoch: 156/350... Loss: 0.07913985724250476... Val Loss: 0.08981295675039291... val accuracy:0.9445440471172333.\n",
      "Epoch: 157/350... Loss: 0.1121613159775734... Val Loss: 0.12626896426081657... val accuracy:0.9445440471172333.\n",
      "Epoch: 158/350... Loss: 0.09259429884453614... Val Loss: 0.1487351506948471... val accuracy:0.9437756240367889.\n",
      "Epoch: 159/350... Loss: 0.08779382752254605... Val Loss: 0.11307325214147568... val accuracy:0.9519723355770111.\n",
      "Epoch: 160/350... Loss: 0.09464659324536721... Val Loss: 0.13255687057971954... val accuracy:0.9597848355770111.\n",
      "Epoch: 161/350... Loss: 0.09477202873677015... Val Loss: 0.11467112973332405... val accuracy:0.9601690471172333.\n",
      "Epoch: 162/350... Loss: 0.1087676656122009... Val Loss: 0.1337235551327467... val accuracy:0.9512038826942444.\n",
      "Epoch: 163/350... Loss: 0.08890921467294295... Val Loss: 0.09427947551012039... val accuracy:0.9523565471172333.\n",
      "Epoch: 164/350... Loss: 0.09528858959674835... Val Loss: 0.1021854616701603... val accuracy:0.9437756240367889.\n",
      "Epoch: 165/350... Loss: 0.08578981831669807... Val Loss: 0.08285501040518284... val accuracy:0.9609375.\n",
      "Epoch: 166/350... Loss: 0.08068748936057091... Val Loss: 0.10700715705752373... val accuracy:0.9601690471172333.\n",
      "Epoch: 167/350... Loss: 0.0872683475414912... Val Loss: 0.12642044201493263... val accuracy:0.9519723355770111.\n",
      "Epoch: 168/350... Loss: 0.10646806346873443... Val Loss: 0.13533172383904457... val accuracy:0.9519723355770111.\n",
      "Epoch: 169/350... Loss: 0.07685040356591344... Val Loss: 0.10483700409531593... val accuracy:0.9445440471172333.\n",
      "Epoch: 170/350... Loss: 0.08261309253672759... Val Loss: 0.09574617072939873... val accuracy:0.9433913826942444.\n",
      "Epoch: 171/350... Loss: 0.08449582615867257... Val Loss: 0.10224829241633415... val accuracy:0.9433913826942444.\n",
      "Epoch: 172/350... Loss: 0.07085864370067914... Val Loss: 0.10125160217285156... val accuracy:0.9433913826942444.\n",
      "Epoch: 173/350... Loss: 0.07276088620225589... Val Loss: 0.11582610756158829... val accuracy:0.9515881240367889.\n",
      "Epoch: 174/350... Loss: 0.07506807645161946... Val Loss: 0.13052218407392502... val accuracy:0.9363473355770111.\n",
      "Epoch: 175/350... Loss: 0.08686042592550318... Val Loss: 0.12350548058748245... val accuracy:0.9363473355770111.\n",
      "Epoch: 176/350... Loss: 0.09715800328801076... Val Loss: 0.10169272124767303... val accuracy:0.9523565471172333.\n",
      "Epoch: 177/350... Loss: 0.08298599518214662... Val Loss: 0.0992450900375843... val accuracy:0.9515881240367889.\n",
      "Epoch: 178/350... Loss: 0.06794053254028161... Val Loss: 0.11304843053221703... val accuracy:0.9594006240367889.\n",
      "Epoch: 179/350... Loss: 0.07548192515969276... Val Loss: 0.09842434152960777... val accuracy:0.9445440471172333.\n",
      "Epoch: 180/350... Loss: 0.06697483298679192... Val Loss: 0.09802688099443913... val accuracy:0.9527407884597778.\n",
      "Epoch: 181/350... Loss: 0.06755968478197853... Val Loss: 0.09805285185575485... val accuracy:0.9601690471172333.\n",
      "Epoch: 182/350... Loss: 0.07221610331907868... Val Loss: 0.11116636171936989... val accuracy:0.9515881240367889.\n",
      "Epoch: 183/350... Loss: 0.06396814466764529... Val Loss: 0.09710496664047241... val accuracy:0.9519723355770111.\n",
      "Epoch: 184/350... Loss: 0.07564903857807319... Val Loss: 0.10708361491560936... val accuracy:0.9523565471172333.\n",
      "Epoch: 185/350... Loss: 0.07792748278006911... Val Loss: 0.12360820546746254... val accuracy:0.9445440471172333.\n",
      "Epoch: 186/350... Loss: 0.08082260253528754... Val Loss: 0.12420044466853142... val accuracy:0.9605532884597778.\n",
      "Epoch: 187/350... Loss: 0.07895555098851521... Val Loss: 0.11480507999658585... val accuracy:0.9523565471172333.\n",
      "Epoch: 188/350... Loss: 0.08988404584427674... Val Loss: 0.11546339839696884... val accuracy:0.9527407884597778.\n",
      "Epoch: 189/350... Loss: 0.09138446021825075... Val Loss: 0.2161816507577896... val accuracy:0.9363473355770111.\n",
      "Epoch: 190/350... Loss: 0.09998471134652694... Val Loss: 0.15969649702310562... val accuracy:0.9523565471172333.\n",
      "Epoch: 191/350... Loss: 0.07317359869678815... Val Loss: 0.12838461622595787... val accuracy:0.9437756240367889.\n",
      "Epoch: 192/350... Loss: 0.06730081133234005... Val Loss: 0.11891108751296997... val accuracy:0.9515881240367889.\n",
      "Epoch: 193/350... Loss: 0.07186292329182227... Val Loss: 0.12272924929857254... val accuracy:0.9597848355770111.\n",
      "Epoch: 194/350... Loss: 0.07323082629591227... Val Loss: 0.13365702703595161... val accuracy:0.9597848355770111.\n",
      "Epoch: 195/350... Loss: 0.08306820721675952... Val Loss: 0.1344575732946396... val accuracy:0.9355788826942444.\n",
      "Epoch: 196/350... Loss: 0.06992619228549302... Val Loss: 0.15752261877059937... val accuracy:0.9351946711540222.\n",
      "Epoch: 197/350... Loss: 0.07353151155014832... Val Loss: 0.1344483196735382... val accuracy:0.9441598355770111.\n",
      "Epoch: 198/350... Loss: 0.07785066512102883... Val Loss: 0.13104721158742905... val accuracy:0.9515881240367889.\n",
      "Epoch: 199/350... Loss: 0.07815423146045457... Val Loss: 0.12019661068916321... val accuracy:0.9597848355770111.\n",
      "Epoch: 200/350... Loss: 0.06405049624542396... Val Loss: 0.16694675758481026... val accuracy:0.9527407884597778.\n",
      "Epoch: 201/350... Loss: 0.06634013758351405... Val Loss: 0.13148131128400564... val accuracy:0.9430071711540222.\n",
      "Epoch: 202/350... Loss: 0.06526267753603558... Val Loss: 0.16130080306902528... val accuracy:0.953125.\n",
      "Epoch: 203/350... Loss: 0.06992810716231664... Val Loss: 0.17835988476872444... val accuracy:0.9273821711540222.\n",
      "Epoch: 204/350... Loss: 0.07665590181325872... Val Loss: 0.1335451453924179... val accuracy:0.9523565471172333.\n",
      "Epoch: 205/350... Loss: 0.10978917498141527... Val Loss: 0.1845889501273632... val accuracy:0.9188012182712555.\n",
      "Epoch: 206/350... Loss: 0.09516719806318481... Val Loss: 0.13693254068493843... val accuracy:0.9441598355770111.\n",
      "Epoch: 207/350... Loss: 0.07338146554927032... Val Loss: 0.12382272630929947... val accuracy:0.9597848355770111.\n",
      "Epoch: 208/350... Loss: 0.08123557828366756... Val Loss: 0.13385862484574318... val accuracy:0.9367315471172333.\n",
      "Epoch: 209/350... Loss: 0.07818092002222936... Val Loss: 0.12982912361621857... val accuracy:0.9519723355770111.\n",
      "Epoch: 210/350... Loss: 0.06278324375549953... Val Loss: 0.1223602443933487... val accuracy:0.9597848355770111.\n",
      "Epoch: 211/350... Loss: 0.06559671151141326... Val Loss: 0.15038441866636276... val accuracy:0.9441598355770111.\n",
      "Epoch: 212/350... Loss: 0.06222698853040735... Val Loss: 0.17658841237425804... val accuracy:0.9601690471172333.\n",
      "Epoch: 213/350... Loss: 0.07112676277756691... Val Loss: 0.1731622815132141... val accuracy:0.9441598355770111.\n",
      "Epoch: 214/350... Loss: 0.06637342972680926... Val Loss: 0.1684083640575409... val accuracy:0.9515881240367889.\n",
      "Epoch: 215/350... Loss: 0.06771729723550379... Val Loss: 0.1421556305140257... val accuracy:0.9605532884597778.\n",
      "Epoch: 216/350... Loss: 0.06976889430855711... Val Loss: 0.17442450299859047... val accuracy:0.9430071711540222.\n",
      "Epoch: 217/350... Loss: 0.05840812483802438... Val Loss: 0.1537109613418579... val accuracy:0.9519723355770111.\n",
      "Epoch: 218/350... Loss: 0.06716484995558858... Val Loss: 0.1266547329723835... val accuracy:0.9601690471172333.\n",
      "Epoch: 219/350... Loss: 0.06746765769397219... Val Loss: 0.15290618687868118... val accuracy:0.9515881240367889.\n",
      "Epoch: 220/350... Loss: 0.05506196695690354... Val Loss: 0.13554440811276436... val accuracy:0.9594006240367889.\n",
      "Epoch: 221/350... Loss: 0.05909563313859204... Val Loss: 0.1554907187819481... val accuracy:0.9359631240367889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 222/350... Loss: 0.06549027577663462... Val Loss: 0.1381024271249771... val accuracy:0.9597848355770111.\n",
      "Epoch: 223/350... Loss: 0.05657323217019439... Val Loss: 0.15052180737257004... val accuracy:0.9359631240367889.\n",
      "Epoch: 224/350... Loss: 0.06404178232575457... Val Loss: 0.1457051858305931... val accuracy:0.9437756240367889.\n",
      "Epoch: 225/350... Loss: 0.07194373027111094... Val Loss: 0.15255916118621826... val accuracy:0.9515881240367889.\n",
      "Epoch: 226/350... Loss: 0.08625805300349991... Val Loss: 0.1478707417845726... val accuracy:0.9601690471172333.\n",
      "Epoch: 227/350... Loss: 0.06913440426190694... Val Loss: 0.1552138552069664... val accuracy:0.9519723355770111.\n",
      "Epoch: 228/350... Loss: 0.06540202628821135... Val Loss: 0.14226212725043297... val accuracy:0.9519723355770111.\n",
      "Epoch: 229/350... Loss: 0.06348146342982848... Val Loss: 0.15222656354308128... val accuracy:0.9594006240367889.\n",
      "Epoch: 230/350... Loss: 0.06709259813942481... Val Loss: 0.17902694456279278... val accuracy:0.953125.\n",
      "Epoch: 231/350... Loss: 0.07116994851579268... Val Loss: 0.18555807694792747... val accuracy:0.9433913826942444.\n",
      "Epoch: 232/350... Loss: 0.06675144548838337... Val Loss: 0.16470637544989586... val accuracy:0.9605532884597778.\n",
      "Epoch: 233/350... Loss: 0.047710461425594985... Val Loss: 0.15442916005849838... val accuracy:0.9519723355770111.\n",
      "Epoch: 234/350... Loss: 0.056294467144956194... Val Loss: 0.22655867785215378... val accuracy:0.9437756240367889.\n",
      "Epoch: 235/350... Loss: 0.07008278680344422... Val Loss: 0.1450606994330883... val accuracy:0.9605532884597778.\n",
      "Epoch: 236/350... Loss: 0.05014215332145492... Val Loss: 0.16893284022808075... val accuracy:0.9519723355770111.\n",
      "Epoch: 237/350... Loss: 0.05682568438351154... Val Loss: 0.1564023494720459... val accuracy:0.9597848355770111.\n",
      "Epoch: 238/350... Loss: 0.05449830973520875... Val Loss: 0.16304009407758713... val accuracy:0.9597848355770111.\n",
      "Epoch: 239/350... Loss: 0.049300369496146836... Val Loss: 0.1679445430636406... val accuracy:0.9672131240367889.\n",
      "Epoch: 240/350... Loss: 0.05164754157885909... Val Loss: 0.18962663412094116... val accuracy:0.9519723355770111.\n",
      "Epoch: 241/350... Loss: 0.058622375751535095... Val Loss: 0.17911992967128754... val accuracy:0.9601690471172333.\n",
      "Epoch: 242/350... Loss: 0.08607338648289442... Val Loss: 0.1886354461312294... val accuracy:0.9449282884597778.\n",
      "Epoch: 243/350... Loss: 0.0842779694745938... Val Loss: 0.19463913142681122... val accuracy:0.9523565471172333.\n",
      "Epoch: 244/350... Loss: 0.06643789370233814... Val Loss: 0.20026520639657974... val accuracy:0.9515881240367889.\n",
      "Epoch: 245/350... Loss: 0.06262451099852721... Val Loss: 0.19135045260190964... val accuracy:0.9441598355770111.\n",
      "Epoch: 246/350... Loss: 0.05279486191769441... Val Loss: 0.18790704756975174... val accuracy:0.9594006240367889.\n",
      "Epoch: 247/350... Loss: 0.055707383124778666... Val Loss: 0.22123540192842484... val accuracy:0.9437756240367889.\n",
      "Epoch: 248/350... Loss: 0.058162413615112506... Val Loss: 0.17435294389724731... val accuracy:0.9597848355770111.\n",
      "Epoch: 249/350... Loss: 0.06296429100135963... Val Loss: 0.2034510001540184... val accuracy:0.9519723355770111.\n",
      "Epoch: 250/350... Loss: 0.05376400022457043... Val Loss: 0.18498052656650543... val accuracy:0.9519723355770111.\n",
      "Epoch: 251/350... Loss: 0.057077726970116295... Val Loss: 0.1737932562828064... val accuracy:0.9601690471172333.\n",
      "Epoch: 252/350... Loss: 0.0637814753378431... Val Loss: 0.1907438263297081... val accuracy:0.9449282884597778.\n",
      "Epoch: 253/350... Loss: 0.06369137562190492... Val Loss: 0.20527268573641777... val accuracy:0.9519723355770111.\n",
      "Epoch: 254/350... Loss: 0.04948288395341175... Val Loss: 0.21913496404886246... val accuracy:0.9519723355770111.\n",
      "Epoch: 255/350... Loss: 0.05391476737956206... Val Loss: 0.2203771360218525... val accuracy:0.9433913826942444.\n",
      "Epoch: 256/350... Loss: 0.06503907187531392... Val Loss: 0.1921691671013832... val accuracy:0.9523565471172333.\n",
      "Epoch: 257/350... Loss: 0.056604685417066015... Val Loss: 0.19615857675671577... val accuracy:0.9605532884597778.\n",
      "Epoch: 258/350... Loss: 0.047269218446065984... Val Loss: 0.20656874030828476... val accuracy:0.9441598355770111.\n",
      "Epoch: 259/350... Loss: 0.052891596686095... Val Loss: 0.20566840842366219... val accuracy:0.9273821711540222.\n",
      "Epoch: 260/350... Loss: 0.07220529314751427... Val Loss: 0.20783285051584244... val accuracy:0.9277663826942444.\n",
      "Epoch: 261/350... Loss: 0.07812663773074746... Val Loss: 0.17862875387072563... val accuracy:0.9519723355770111.\n",
      "Epoch: 262/350... Loss: 0.08342367333049576... Val Loss: 0.19814734905958176... val accuracy:0.9519723355770111.\n",
      "Epoch: 263/350... Loss: 0.0946713446949919... Val Loss: 0.21346136182546616... val accuracy:0.9266137182712555.\n",
      "Epoch: 264/350... Loss: 0.06394898208479087... Val Loss: 0.20937377959489822... val accuracy:0.9519723355770111.\n",
      "Epoch: 265/350... Loss: 0.05247557535767555... Val Loss: 0.21314121037721634... val accuracy:0.9519723355770111.\n",
      "Epoch: 266/350... Loss: 0.058806532683471836... Val Loss: 0.22607915103435516... val accuracy:0.9523565471172333.\n",
      "Epoch: 267/350... Loss: 0.05298146318333844... Val Loss: 0.21010971069335938... val accuracy:0.9512038826942444.\n",
      "Epoch: 268/350... Loss: 0.06601221145441134... Val Loss: 0.22392939776182175... val accuracy:0.9519723355770111.\n",
      "Epoch: 269/350... Loss: 0.061644866674517594... Val Loss: 0.18774345517158508... val accuracy:0.9523565471172333.\n",
      "Epoch: 270/350... Loss: 0.04925261748333772... Val Loss: 0.21565736830234528... val accuracy:0.9597848355770111.\n",
      "Epoch: 271/350... Loss: 0.04455133721542855... Val Loss: 0.23067812621593475... val accuracy:0.9523565471172333.\n",
      "Epoch: 272/350... Loss: 0.0417867178718249... Val Loss: 0.257037416100502... val accuracy:0.9433913826942444.\n",
      "Epoch: 273/350... Loss: 0.06788561632856727... Val Loss: 0.28930582851171494... val accuracy:0.9449282884597778.\n",
      "Epoch: 274/350... Loss: 0.06920332127871613... Val Loss: 0.25172336399555206... val accuracy:0.9519723355770111.\n",
      "Epoch: 275/350... Loss: 0.05712891115884607... Val Loss: 0.2295135036110878... val accuracy:0.9527407884597778.\n",
      "Epoch: 276/350... Loss: 0.0699542857085665... Val Loss: 0.21178361028432846... val accuracy:0.9363473355770111.\n",
      "Epoch: 277/350... Loss: 0.0645318649088343... Val Loss: 0.17610281333327293... val accuracy:0.9675973355770111.\n",
      "Epoch: 278/350... Loss: 0.05258488554197053... Val Loss: 0.23514775186777115... val accuracy:0.9523565471172333.\n",
      "Epoch: 279/350... Loss: 0.06444149736004572... Val Loss: 0.19254181161522865... val accuracy:0.9515881240367889.\n",
      "Epoch: 280/350... Loss: 0.06561261260261138... Val Loss: 0.2025490328669548... val accuracy:0.9519723355770111.\n",
      "Epoch: 281/350... Loss: 0.06430353969335556... Val Loss: 0.22143887728452682... val accuracy:0.9601690471172333.\n",
      "Epoch: 282/350... Loss: 0.08162513887509704... Val Loss: 0.2118883579969406... val accuracy:0.9523565471172333.\n",
      "Epoch: 283/350... Loss: 0.060920996591448784... Val Loss: 0.19645053520798683... val accuracy:0.9601690471172333.\n",
      "Epoch: 284/350... Loss: 0.060688005139430366... Val Loss: 0.19970586709678173... val accuracy:0.9445440471172333.\n",
      "Epoch: 285/350... Loss: 0.05498342914506793... Val Loss: 0.20209214091300964... val accuracy:0.9512038826942444.\n",
      "Epoch: 286/350... Loss: 0.04897584797193607... Val Loss: 0.19487768411636353... val accuracy:0.9515881240367889.\n",
      "Epoch: 287/350... Loss: 0.04679759591817856... Val Loss: 0.21358776837587357... val accuracy:0.9433913826942444.\n",
      "Epoch: 288/350... Loss: 0.062029560251782336... Val Loss: 0.1998368576169014... val accuracy:0.9523565471172333.\n",
      "Epoch: 289/350... Loss: 0.05408040092637142... Val Loss: 0.23749686777591705... val accuracy:0.9441598355770111.\n",
      "Epoch: 290/350... Loss: 0.05788688904916247... Val Loss: 0.23808158934116364... val accuracy:0.9441598355770111.\n",
      "Epoch: 291/350... Loss: 0.06455201733236511... Val Loss: 0.2501353397965431... val accuracy:0.9515881240367889.\n",
      "Epoch: 292/350... Loss: 0.0634986232034862... Val Loss: 0.2204400822520256... val accuracy:0.9515881240367889.\n",
      "Epoch: 293/350... Loss: 0.09230428949619333... Val Loss: 0.24977749213576317... val accuracy:0.9523565471172333.\n",
      "Epoch: 294/350... Loss: 0.08982003107666969... Val Loss: 0.24863115698099136... val accuracy:0.9437756240367889.\n",
      "Epoch: 295/350... Loss: 0.06426027106742065... Val Loss: 0.24789141863584518... val accuracy:0.9515881240367889.\n",
      "Epoch: 296/350... Loss: 0.05440844238425294... Val Loss: 0.227705180644989... val accuracy:0.9523565471172333.\n",
      "Epoch: 297/350... Loss: 0.05040507980932792... Val Loss: 0.2472766637802124... val accuracy:0.9437756240367889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 298/350... Loss: 0.04352121784662207... Val Loss: 0.2133723497390747... val accuracy:0.9453125.\n",
      "Epoch: 299/350... Loss: 0.06748188535372417... Val Loss: 0.2608672082424164... val accuracy:0.9199538826942444.\n",
      "Epoch: 300/350... Loss: 0.08482915349304676... Val Loss: 0.2158236801624298... val accuracy:0.9519723355770111.\n",
      "Epoch: 301/350... Loss: 0.049137724097818136... Val Loss: 0.2465229518711567... val accuracy:0.9445440471172333.\n",
      "Epoch: 302/350... Loss: 0.046068408681700625... Val Loss: 0.19633220881223679... val accuracy:0.9519723355770111.\n",
      "Epoch: 303/350... Loss: 0.05006597703322768... Val Loss: 0.19274675101041794... val accuracy:0.9519723355770111.\n",
      "Epoch: 304/350... Loss: 0.05301081327100595... Val Loss: 0.23929092288017273... val accuracy:0.9601690471172333.\n",
      "Epoch: 305/350... Loss: 0.05598393936331073... Val Loss: 0.2876356989145279... val accuracy:0.9355788826942444.\n",
      "Epoch: 306/350... Loss: 0.07488866158140202... Val Loss: 0.2732059136033058... val accuracy:0.9512038826942444.\n",
      "Epoch: 307/350... Loss: 0.06036501657217741... Val Loss: 0.22848968394100666... val accuracy:0.9609375.\n",
      "Epoch: 308/350... Loss: 0.07717934406052034... Val Loss: 0.2604585736989975... val accuracy:0.9437756240367889.\n",
      "Epoch: 309/350... Loss: 0.058107607842733465... Val Loss: 0.2580169662833214... val accuracy:0.9441598355770111.\n",
      "Epoch: 310/350... Loss: 0.05214833623419205... Val Loss: 0.2102329172194004... val accuracy:0.9605532884597778.\n",
      "Epoch: 311/350... Loss: 0.043518557058026396... Val Loss: 0.23703794181346893... val accuracy:0.9441598355770111.\n",
      "Epoch: 312/350... Loss: 0.04380144613484541... Val Loss: 0.21570518612861633... val accuracy:0.9597848355770111.\n",
      "Epoch: 313/350... Loss: 0.04077479615807533... Val Loss: 0.2494646981358528... val accuracy:0.9519723355770111.\n",
      "Epoch: 314/350... Loss: 0.05105952142427365... Val Loss: 0.2360060214996338... val accuracy:0.9605532884597778.\n",
      "Epoch: 315/350... Loss: 0.053961991177250944... Val Loss: 0.26360125839710236... val accuracy:0.9527407884597778.\n",
      "Epoch: 316/350... Loss: 0.055263139152278505... Val Loss: 0.2693758085370064... val accuracy:0.9445440471172333.\n",
      "Epoch: 317/350... Loss: 0.046239715069532394... Val Loss: 0.23368602991104126... val accuracy:0.9597848355770111.\n",
      "Epoch: 318/350... Loss: 0.042451700350890555... Val Loss: 0.26044458895921707... val accuracy:0.9430071711540222.\n",
      "Epoch: 319/350... Loss: 0.07462010206654668... Val Loss: 0.31317567825317383... val accuracy:0.9430071711540222.\n",
      "Epoch: 320/350... Loss: 0.06624250890066226... Val Loss: 0.23359260708093643... val accuracy:0.9601690471172333.\n",
      "Epoch: 321/350... Loss: 0.05039995225767294... Val Loss: 0.24046199768781662... val accuracy:0.9601690471172333.\n",
      "Epoch: 322/350... Loss: 0.05034052596117059... Val Loss: 0.26311665028333664... val accuracy:0.9433913826942444.\n",
      "Epoch: 323/350... Loss: 0.040147640431920685... Val Loss: 0.2413574606180191... val accuracy:0.9519723355770111.\n",
      "Epoch: 324/350... Loss: 0.03817867084095875... Val Loss: 0.25930094718933105... val accuracy:0.9433913826942444.\n",
      "Epoch: 325/350... Loss: 0.04303499311208725... Val Loss: 0.2617884650826454... val accuracy:0.9515881240367889.\n",
      "Epoch: 326/350... Loss: 0.04294810133675734... Val Loss: 0.25222957134246826... val accuracy:0.9601690471172333.\n",
      "Epoch: 327/350... Loss: 0.05718582309782505... Val Loss: 0.2623044177889824... val accuracy:0.9601690471172333.\n",
      "Epoch: 328/350... Loss: 0.04731402499601245... Val Loss: 0.2694278657436371... val accuracy:0.9519723355770111.\n",
      "Epoch: 329/350... Loss: 0.04475089721381664... Val Loss: 0.30506860092282295... val accuracy:0.9430071711540222.\n",
      "Epoch: 330/350... Loss: 0.04226365794117252... Val Loss: 0.2629445493221283... val accuracy:0.9515881240367889.\n",
      "Epoch: 331/350... Loss: 0.03510765529548129... Val Loss: 0.26474927365779877... val accuracy:0.9519723355770111.\n",
      "Epoch: 332/350... Loss: 0.04029176446298758... Val Loss: 0.2827255427837372... val accuracy:0.9519723355770111.\n",
      "Epoch: 333/350... Loss: 0.035024712017426886... Val Loss: 0.2861119210720062... val accuracy:0.9601690471172333.\n",
      "Epoch: 334/350... Loss: 0.0348116351912419... Val Loss: 0.27831166982650757... val accuracy:0.9519723355770111.\n",
      "Epoch: 335/350... Loss: 0.05688465223647654... Val Loss: 0.27907025814056396... val accuracy:0.9594006240367889.\n",
      "Epoch: 336/350... Loss: 0.03888434908973674... Val Loss: 0.30246424674987793... val accuracy:0.9523565471172333.\n",
      "Epoch: 337/350... Loss: 0.04616107093170285... Val Loss: 0.2878507971763611... val accuracy:0.9519723355770111.\n",
      "Epoch: 338/350... Loss: 0.04305676215638717... Val Loss: 0.2727683559060097... val accuracy:0.9515881240367889.\n",
      "Epoch: 339/350... Loss: 0.04433252802118659... Val Loss: 0.2753799855709076... val accuracy:0.9601690471172333.\n",
      "Epoch: 340/350... Loss: 0.06127728351081411... Val Loss: 0.28333473950624466... val accuracy:0.9441598355770111.\n",
      "Epoch: 341/350... Loss: 0.06668618538727362... Val Loss: 0.3013227581977844... val accuracy:0.9515881240367889.\n",
      "Epoch: 342/350... Loss: 0.05973398250838121... Val Loss: 0.2919582948088646... val accuracy:0.9433913826942444.\n",
      "Epoch: 343/350... Loss: 0.04530127579346299... Val Loss: 0.27967797964811325... val accuracy:0.9515881240367889.\n",
      "Epoch: 344/350... Loss: 0.04861986543983221... Val Loss: 0.28504860401153564... val accuracy:0.9512038826942444.\n",
      "Epoch: 345/350... Loss: 0.04926438148443898... Val Loss: 0.31711238622665405... val accuracy:0.9523565471172333.\n",
      "Epoch: 346/350... Loss: 0.04313818629210194... Val Loss: 0.30646783113479614... val accuracy:0.9449282884597778.\n",
      "Epoch: 347/350... Loss: 0.03666392620652914... Val Loss: 0.2844097316265106... val accuracy:0.9519723355770111.\n",
      "Epoch: 348/350... Loss: 0.040957199642434716... Val Loss: 0.27367008477449417... val accuracy:0.9363473355770111.\n",
      "Epoch: 349/350... Loss: 0.0474016695904235... Val Loss: 0.30122190713882446... val accuracy:0.9430071711540222.\n",
      "Epoch: 350/350... Loss: 0.0461587798781693... Val Loss: 0.28443909902125597... val accuracy:0.953125.\n",
      "min loss 0.08169496431946754\n",
      "Training time is: 22.73693871498108 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0320a5a278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = LSTM(1,3,64,2) #512,2 0.983  256,2 0.983 ,64 ,2 0.984,32,2,0.983,256,4.0.983\n",
    "from time import time\n",
    "if train_on_gpu:\n",
    "    net.cuda()\n",
    "start = time()\n",
    "epochs = 350\n",
    "accuracy = train(net,epochs,train_loader,valid_loader,clip=5,lr=0.00128)\n",
    "print('Training time is:',time()-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0320178cc0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(accuracy,color='b',label='accuracy')\n",
    "#plt.title('Accuracy_Trend')\n",
    "#plt.xlabel('Epoches')\n",
    "#plt.ylabel('Accuracy')\n",
    "plt.plot(accuracy,color='b',label='准确率')\n",
    "plt.title('准确率变化')\n",
    "plt.xlabel('迭代次数')\n",
    "plt.ylabel('准确率')\n",
    "plt.legend()\n",
    "plt.savefig('behavior_image/accuracy_lstm_behavior_old1.svg',dpi=300)\n",
    "plt.savefig('behavior_image/accuracy_lstm_behavior_old1.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.081629\n",
      "\n",
      "Test Accuracy of left:100.0000(42/42)\n",
      "Test Accuracy of keep:95.9184(47/49)\n",
      "Test Accuracy of right:97.0588(33/34)\n",
      "Test Accuracy(Overall):97.6000 (122/125)\n",
      "Test loss: 0.063 Test Accuracy:0.9757940471172333\n"
     ]
    }
   ],
   "source": [
    "net_test = LSTM(1,3,64,2)\n",
    "net_test.load_state_dict(torch.load('model/lstm_behavior_prediction_old.pt'))\n",
    "if train_on_gpu:\n",
    "    net_test.cuda()\n",
    "    \n",
    "\n",
    "test(net_test,test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.0007095098495483399\n",
      "tensor([[-19.9564,  -0.9479,  20.0578],\n",
      "        [-19.9564,  -0.9479,  20.0578],\n",
      "        [-19.9564,  -0.9479,  20.0578],\n",
      "        ...,\n",
      "        [-19.9564,  -0.9479,  20.0578],\n",
      "        [-19.9564,  -0.9479,  20.0578],\n",
      "        [-19.9564,  -0.9479,  20.0578]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "net_test.cuda().eval()\n",
    "h = net_test.init_hidden(50000)\n",
    "h = tuple([each.data for each in h])\n",
    "example = torch.ones(50000,4,1).cuda()\n",
    "t = time()\n",
    "out,h = net_test(example,h)\n",
    "print('time',((time()-t)*1000)/50000)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
