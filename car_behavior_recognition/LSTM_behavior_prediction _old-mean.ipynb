{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "def labeltoint(label):\n",
    "    if label == 'left':\n",
    "        label = 0\n",
    "    if label == 'keep':\n",
    "        label = 1\n",
    "    if label == 'right':\n",
    "        label = 2\n",
    "    return label\n",
    "\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('data1/train.json', 'r') as f:\n",
    "    j = json.load(f)\n",
    "  #  print(j.keys())\n",
    "    X_train = j['states']\n",
    "    Y_train = j['labels']\n",
    "    for i in range(len(Y_train)):\n",
    "        Y_train[i] = labeltoint(Y_train[i])\n",
    "  #  print(Y_train)\n",
    "\n",
    "with open('data1/test.json', 'r') as f:\n",
    "    j = json.load(f)\n",
    "    X_test = j['states']\n",
    "    Y_test = j['labels']\n",
    "    for i in range(len(Y_test)):\n",
    "        Y_test[i] = labeltoint(Y_test[i])\n",
    "\n",
    "split_frac = 0.8\n",
    "X_train, Y_train, X_test, Y_test = np.array(X_train).astype(np.float32), np.array(Y_train).astype(np.long), np.array(\n",
    "    X_test).astype(np.float32), np.array(Y_test).astype(np.long)\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "val_x, test_x = X_test[:len(X_test) // 2], X_test[len(X_test) // 2:]\n",
    "val_y, test_y = Y_test[:len(Y_test) // 2], Y_test[len(Y_test) // 2:]\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy((X_train)), torch.from_numpy(Y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers,dropout=0, batch_first=True)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim,hidden_dim*2)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        self.fc2 = nn.Linear(X_train.shape[1],output_size)\n",
    "    def forward(self, x, hidden):\n",
    "        # x (batch_size, seq_length, input_size)\n",
    "        # hidden (n_layers, batch_size, hidden_dim)\n",
    "        # r_out (batch_size, time_step, hidden_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.lstm(x, hidden)\n",
    "        #print(r_out.shape)\n",
    "        r_out = torch.mean(r_out,dim=1).squeeze()\n",
    "        #print(r_out.shape)\n",
    "        output= self.fc1(r_out)\n",
    "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
    "        \"\"\"\n",
    "        r_out = r_out.contiguous().view(-1, self.hidden_dim)  \n",
    "        \n",
    "        # get final output \n",
    "        output = self.fc1(r_out)\n",
    "        output = self.fc(output)\n",
    "        output = output.view(batch_size,-1,3)\n",
    "        output = output[:,-1]\n",
    "       \"\"\"\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_on_gpu = True\n",
    "else:\n",
    "    train_on_gpu = False\n",
    "\n",
    "\n",
    "# In[8]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,epochs,train_loader,valid_loader,clip,lr = 0.0002):\n",
    "    # train for some number of epochs\n",
    "    # loss and optimization functions\n",
    "\n",
    "    loss_min = np.inf\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    counter = 0\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    accuracies_e = []\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        net.train()\n",
    "        # batch loop\n",
    "        train_loss = []\n",
    "        for inputs, labels in train_loader:\n",
    "            h = net.init_hidden(inputs.shape[0])\n",
    "            h = tuple([each.data for each in h])\n",
    "            inputs = inputs.unsqueeze(2)\n",
    "            if (train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "          #  print(output.shape,labels.shape)\n",
    "           # print(output[:1])\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            # loss stats\n",
    "                # Get validation loss\n",
    "\n",
    "        val_losses = []\n",
    "        net.eval()\n",
    "        accuracies = []\n",
    "        for inputs, labels in valid_loader:\n",
    "            val_h = net.init_hidden(inputs.shape[0])\n",
    "            inputs = inputs.unsqueeze(2)\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                   # val_h = tuple([each.data for each in val_h])\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "            if (train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            output, val_h = net(inputs, val_h)\n",
    "\n",
    "            val_loss = criterion(output, labels)\n",
    "            _, class_ = torch.max(output, dim=1)\n",
    "            equal = class_ == labels.view(class_.shape)\n",
    "            accuracy = torch.mean(equal.type(torch.FloatTensor)).item()\n",
    "            val_losses.append(val_loss.item())\n",
    "            accuracies.append(accuracy)\n",
    "                \n",
    "\n",
    "        net.train()\n",
    "        losses_train.append(np.mean(train_loss))\n",
    "        losses_valid.append(np.mean(val_losses))\n",
    "        accuracies_e.append(np.mean(np.mean(accuracies)))\n",
    "        print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "                      \"Loss: {}...\".format(np.mean(train_loss)),\n",
    "                      \"Val Loss: {}...\".format(np.mean(val_losses)),\n",
    "                      \"val accuracy:{}.\".format(np.mean(accuracies))\n",
    "                     )\n",
    "        if np.mean(val_losses) < loss_min:\n",
    "            print('Val loss decreased...')\n",
    "            torch.save(net.state_dict(),'model/lstm_behavior_prediction_old_mean.pt')\n",
    "            loss_min = np.mean(val_losses)\n",
    "    print('min loss',loss_min)\n",
    "    plt.plot(losses_train,color='r',label='train_loss')\n",
    "    plt.plot(losses_valid,color='g',label='valid_loss')\n",
    "    plt.title('Loss_Trend')\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('behavior_image/loss_lstm_behavior_old_mean.svg')\n",
    "    \n",
    "    return accuracies_e\n",
    "                            \n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def test(net,test_loader):\n",
    "    # Get test data loss and accuracy\n",
    "    lr = 0.001\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_losses = []  # track loss\n",
    "    accuracies = []\n",
    "    net.eval()\n",
    "    # iterate over test data\n",
    "    class_correct = np.zeros(3)\n",
    "    class_total = np.zeros(3)\n",
    "    classes = ['left','keep','right']\n",
    "    for inputs, y in test_loader:\n",
    "        h = net.init_hidden(inputs.shape[0])\n",
    "        inputs = inputs.unsqueeze(2)\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            inputs, y = inputs.cuda(), y.cuda()\n",
    "        # get predicted outputs\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate loss\n",
    "        test_loss = criterion(output, y)\n",
    "        _, class_ = torch.max(output, dim=1)\n",
    "        equal = class_ == y.view(class_.shape)\n",
    "        for i in range(y.shape[0]):\n",
    "            label = y.data[i].item()\n",
    "            class_correct[label] += equal[i].item()\n",
    "            class_total[label] += 1\n",
    "        accuracy = torch.mean(equal.type(torch.FloatTensor)).item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # -- stats! -- ##\n",
    "    # avg test loss\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "    for i in range(3):\n",
    "        if class_total[i]>0:\n",
    "            print('Test Accuracy of {}:{:.4f}({}/{})'.format(classes[i],100*class_correct[i]/class_total[i],\n",
    "                 int(np.sum(class_correct[i])),\n",
    "                 int(np.sum(class_total[i]))))\n",
    "        else:\n",
    "            print('Test Accuracy of {}:N/A(no examples)'.format(classes[i]))\n",
    "    print('Test Accuracy(Overall):{} ({}/{})'.format(100*np.sum(class_correct)/np.sum(class_total),\n",
    "                                                    int(np.sum(class_correct)),\n",
    "                                                    int(np.sum(class_total))))\n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_losses)),'Test Accuracy:{}'.format(np.mean(accuracies)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/350... Loss: 2.239166021347046... Val Loss: 1.1522635221481323... val accuracy:0.24833503365516663.\n",
      "Val loss decreased...\n",
      "Epoch: 2/350... Loss: 1.126069575548172... Val Loss: 1.1205925345420837... val accuracy:0.24795082211494446.\n",
      "Val loss decreased...\n",
      "Epoch: 3/350... Loss: 1.0913799504439037... Val Loss: 1.1063052415847778... val accuracy:0.40061475336551666.\n",
      "Val loss decreased...\n",
      "Epoch: 4/350... Loss: 1.0924004862705867... Val Loss: 1.1715622544288635... val accuracy:0.4002305269241333.\n",
      "Epoch: 5/350... Loss: 1.1101661523183186... Val Loss: 1.0991519689559937... val accuracy:0.39869365096092224.\n",
      "Val loss decreased...\n",
      "Epoch: 6/350... Loss: 1.0907798906167347... Val Loss: 1.141026258468628... val accuracy:0.3983094245195389.\n",
      "Epoch: 7/350... Loss: 1.0998756488164265... Val Loss: 1.175570011138916... val accuracy:0.2464139312505722.\n",
      "Epoch: 8/350... Loss: 1.1106556157271068... Val Loss: 1.1551406383514404... val accuracy:0.3983094245195389.\n",
      "Epoch: 9/350... Loss: 1.0955234567324321... Val Loss: 1.120095431804657... val accuracy:0.40061475336551666.\n",
      "Epoch: 10/350... Loss: 1.1121885279814403... Val Loss: 1.1577355861663818... val accuracy:0.40061475336551666.\n",
      "Epoch: 11/350... Loss: 1.1128734648227692... Val Loss: 1.1578799486160278... val accuracy:0.4013831913471222.\n",
      "Epoch: 12/350... Loss: 1.1110292573769887... Val Loss: 1.081574022769928... val accuracy:0.4009989798069.\n",
      "Val loss decreased...\n",
      "Epoch: 13/350... Loss: 1.1143283446629841... Val Loss: 1.091848611831665... val accuracy:0.39869365096092224.\n",
      "Epoch: 14/350... Loss: 1.0843408902486165... Val Loss: 1.0806829333305359... val accuracy:0.38422131538391113.\n",
      "Val loss decreased...\n",
      "Epoch: 15/350... Loss: 1.0953066448370616... Val Loss: 1.1123608946800232... val accuracy:0.3912653625011444.\n",
      "Epoch: 16/350... Loss: 1.1022177239259083... Val Loss: 1.1208115220069885... val accuracy:0.40061475336551666.\n",
      "Epoch: 17/350... Loss: 1.1361093819141388... Val Loss: 1.0875182747840881... val accuracy:0.38422131538391113.\n",
      "Epoch: 18/350... Loss: 1.1180392801761627... Val Loss: 1.085925042629242... val accuracy:0.3983094245195389.\n",
      "Epoch: 19/350... Loss: 1.084408660729726... Val Loss: 1.094501793384552... val accuracy:0.39946208894252777.\n",
      "Epoch: 20/350... Loss: 1.0850060780843098... Val Loss: 1.112365961074829... val accuracy:0.4002305269241333.\n",
      "Epoch: 21/350... Loss: 1.0917486051718395... Val Loss: 1.1512017846107483... val accuracy:0.24718237668275833.\n",
      "Epoch: 22/350... Loss: 1.100339283545812... Val Loss: 1.0928688049316406... val accuracy:0.39869365096092224.\n",
      "Epoch: 23/350... Loss: 1.0888842940330505... Val Loss: 1.094766616821289... val accuracy:0.40765881538391113.\n",
      "Epoch: 24/350... Loss: 1.1002473533153534... Val Loss: 1.116919219493866... val accuracy:0.40061475336551666.\n",
      "Epoch: 25/350... Loss: 1.1104097962379456... Val Loss: 1.0892210006713867... val accuracy:0.40061475336551666.\n",
      "Epoch: 26/350... Loss: 1.0856750806172688... Val Loss: 1.0884664058685303... val accuracy:0.39088115096092224.\n",
      "Epoch: 27/350... Loss: 1.1005999545256298... Val Loss: 1.1222808361053467... val accuracy:0.39869365096092224.\n",
      "Epoch: 28/350... Loss: 1.1048185129960377... Val Loss: 1.1170222163200378... val accuracy:0.39946208894252777.\n",
      "Epoch: 29/350... Loss: 1.1104536801576614... Val Loss: 1.0815224051475525... val accuracy:0.41623975336551666.\n",
      "Epoch: 30/350... Loss: 1.101448893547058... Val Loss: 1.0918543338775635... val accuracy:0.4002305269241333.\n",
      "Epoch: 31/350... Loss: 1.0913338164488475... Val Loss: 1.0957840085029602... val accuracy:0.39280225336551666.\n",
      "Epoch: 32/350... Loss: 1.0850119590759277... Val Loss: 1.0842986702919006... val accuracy:0.4013831913471222.\n",
      "Epoch: 33/350... Loss: 1.091471274693807... Val Loss: 1.0907983779907227... val accuracy:0.3533555269241333.\n",
      "Epoch: 34/350... Loss: 1.0871206323305767... Val Loss: 1.1322233080863953... val accuracy:0.24910348653793335.\n",
      "Epoch: 35/350... Loss: 1.1215010583400726... Val Loss: 1.2078018188476562... val accuracy:0.3744876980781555.\n",
      "Epoch: 36/350... Loss: 1.1084982653458912... Val Loss: 1.107297122478485... val accuracy:0.3846055269241333.\n",
      "Epoch: 37/350... Loss: 1.1013241807619731... Val Loss: 1.1273983120918274... val accuracy:0.35847848653793335.\n",
      "Epoch: 38/350... Loss: 1.0971517364184062... Val Loss: 1.0841029286384583... val accuracy:0.4236680269241333.\n",
      "Epoch: 39/350... Loss: 1.081718534231186... Val Loss: 1.130871295928955... val accuracy:0.3904969245195389.\n",
      "Epoch: 40/350... Loss: 1.1028505961100261... Val Loss: 1.1057438850402832... val accuracy:0.3912653625011444.\n",
      "Epoch: 41/350... Loss: 1.0855879286924999... Val Loss: 1.103371798992157... val accuracy:0.40765881538391113.\n",
      "Epoch: 42/350... Loss: 1.0831399857997894... Val Loss: 1.1263258457183838... val accuracy:0.31160348653793335.\n",
      "Epoch: 43/350... Loss: 1.0967838366826375... Val Loss: 1.0714282989501953... val accuracy:0.3846055269241333.\n",
      "Val loss decreased...\n",
      "Epoch: 44/350... Loss: 1.074879765510559... Val Loss: 1.0385258793830872... val accuracy:0.39946208894252777.\n",
      "Val loss decreased...\n",
      "Epoch: 45/350... Loss: 1.026167944073677... Val Loss: 1.015074372291565... val accuracy:0.4337858557701111.\n",
      "Val loss decreased...\n",
      "Epoch: 46/350... Loss: 1.0108860085407894... Val Loss: 1.0103970170021057... val accuracy:0.41623975336551666.\n",
      "Val loss decreased...\n",
      "Epoch: 47/350... Loss: 1.0125030775864918... Val Loss: 1.0191795825958252... val accuracy:0.43109631538391113.\n",
      "Epoch: 48/350... Loss: 0.9886796176433563... Val Loss: 0.9867773950099945... val accuracy:0.44198256731033325.\n",
      "Val loss decreased...\n",
      "Epoch: 49/350... Loss: 0.9803813497225443... Val Loss: 1.0409245491027832... val accuracy:0.4166239798069.\n",
      "Epoch: 50/350... Loss: 0.9777048279841741... Val Loss: 0.9863061606884003... val accuracy:0.4638831913471222.\n",
      "Val loss decreased...\n",
      "Epoch: 51/350... Loss: 0.9663132180770239... Val Loss: 0.9540638029575348... val accuracy:0.5677510201931.\n",
      "Val loss decreased...\n",
      "Epoch: 52/350... Loss: 0.9596850574016571... Val Loss: 0.988849014043808... val accuracy:0.4415983557701111.\n",
      "Epoch: 53/350... Loss: 0.9443672994772593... Val Loss: 0.9523755609989166... val accuracy:0.47207991778850555.\n",
      "Val loss decreased...\n",
      "Epoch: 54/350... Loss: 0.9036856293678284... Val Loss: 0.9288757145404816... val accuracy:0.5662141442298889.\n",
      "Val loss decreased...\n",
      "Epoch: 55/350... Loss: 0.8952220529317856... Val Loss: 0.9170909821987152... val accuracy:0.5033299177885056.\n",
      "Val loss decreased...\n",
      "Epoch: 56/350... Loss: 0.8820518602927526... Val Loss: 0.8751563429832458... val accuracy:0.5427766442298889.\n",
      "Val loss decreased...\n",
      "Epoch: 57/350... Loss: 0.8509433815876642... Val Loss: 0.8391034305095673... val accuracy:0.631787896156311.\n",
      "Val loss decreased...\n",
      "Epoch: 58/350... Loss: 0.8179070601860682... Val Loss: 0.8946495354175568... val accuracy:0.5122950673103333.\n",
      "Epoch: 59/350... Loss: 0.79506383339564... Val Loss: 0.8015668094158173... val accuracy:0.6645748019218445.\n",
      "Val loss decreased...\n",
      "Epoch: 60/350... Loss: 0.7421266486247381... Val Loss: 0.7642184495925903... val accuracy:0.6466444730758667.\n",
      "Val loss decreased...\n",
      "Epoch: 61/350... Loss: 0.6998656938473383... Val Loss: 0.7052148580551147... val accuracy:0.7379610538482666.\n",
      "Val loss decreased...\n",
      "Epoch: 62/350... Loss: 0.6366380006074905... Val Loss: 0.6254697740077972... val accuracy:0.7110655605792999.\n",
      "Val loss decreased...\n",
      "Epoch: 63/350... Loss: 0.5809911911686262... Val Loss: 0.6001888811588287... val accuracy:0.7918801307678223.\n",
      "Val loss decreased...\n",
      "Epoch: 64/350... Loss: 0.5103276421626409... Val Loss: 0.4632285535335541... val accuracy:0.8637295067310333.\n",
      "Val loss decreased...\n",
      "Epoch: 65/350... Loss: 0.3963276172677676... Val Loss: 0.3629262298345566... val accuracy:0.8887038826942444.\n",
      "Val loss decreased...\n",
      "Epoch: 66/350... Loss: 0.31664767985542613... Val Loss: 0.40733665227890015... val accuracy:0.8410604596138.\n",
      "Epoch: 67/350... Loss: 0.3032119845350583... Val Loss: 0.30695053935050964... val accuracy:0.8898565471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 68/350... Loss: 0.26933902377883595... Val Loss: 0.28110626339912415... val accuracy:0.8949795067310333.\n",
      "Val loss decreased...\n",
      "Epoch: 69/350... Loss: 0.2394834359486898... Val Loss: 0.2726513668894768... val accuracy:0.9050973355770111.\n",
      "Val loss decreased...\n",
      "Epoch: 70/350... Loss: 0.22699108719825745... Val Loss: 0.29500849545001984... val accuracy:0.9031762182712555.\n",
      "Epoch: 71/350... Loss: 0.21097696448365846... Val Loss: 0.26760151982307434... val accuracy:0.8887038826942444.\n",
      "Val loss decreased...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/350... Loss: 0.20058730120460191... Val Loss: 0.2565801665186882... val accuracy:0.9043288826942444.\n",
      "Val loss decreased...\n",
      "Epoch: 73/350... Loss: 0.1856839476774136... Val Loss: 0.23912379145622253... val accuracy:0.9039446711540222.\n",
      "Val loss decreased...\n",
      "Epoch: 74/350... Loss: 0.17312073521316051... Val Loss: 0.21856236830353737... val accuracy:0.9191854596138.\n",
      "Val loss decreased...\n",
      "Epoch: 75/350... Loss: 0.17602457044025263... Val Loss: 0.23700828850269318... val accuracy:0.9281506240367889.\n",
      "Epoch: 76/350... Loss: 0.17535615774492422... Val Loss: 0.2174099236726761... val accuracy:0.9512038826942444.\n",
      "Val loss decreased...\n",
      "Epoch: 77/350... Loss: 0.1627663510541121... Val Loss: 0.22469522804021835... val accuracy:0.9433913826942444.\n",
      "Epoch: 78/350... Loss: 0.14650013608237109... Val Loss: 0.1931963972747326... val accuracy:0.9437756240367889.\n",
      "Val loss decreased...\n",
      "Epoch: 79/350... Loss: 0.13361677279074988... Val Loss: 0.23194487392902374... val accuracy:0.9195696711540222.\n",
      "Epoch: 80/350... Loss: 0.15384315513074398... Val Loss: 0.2162635177373886... val accuracy:0.9437756240367889.\n",
      "Epoch: 81/350... Loss: 0.16727249634762606... Val Loss: 0.3017291873693466... val accuracy:0.8961321711540222.\n",
      "Epoch: 82/350... Loss: 0.14492563220361868... Val Loss: 0.2174166850745678... val accuracy:0.9214907884597778.\n",
      "Epoch: 83/350... Loss: 0.12035109599431355... Val Loss: 0.23581574112176895... val accuracy:0.9359631240367889.\n",
      "Epoch: 84/350... Loss: 0.11783856153488159... Val Loss: 0.19678890705108643... val accuracy:0.9363473355770111.\n",
      "Epoch: 85/350... Loss: 0.13672318247457346... Val Loss: 0.33312641084194183... val accuracy:0.8961321711540222.\n",
      "Epoch: 86/350... Loss: 0.1524608638137579... Val Loss: 0.22772350907325745... val accuracy:0.9281506240367889.\n",
      "Epoch: 87/350... Loss: 0.11736125747362773... Val Loss: 0.1850852109491825... val accuracy:0.9512038826942444.\n",
      "Val loss decreased...\n",
      "Epoch: 88/350... Loss: 0.10513539891690016... Val Loss: 0.2020254284143448... val accuracy:0.9430071711540222.\n",
      "Epoch: 89/350... Loss: 0.09589898524185021... Val Loss: 0.20956721156835556... val accuracy:0.9437756240367889.\n",
      "Epoch: 90/350... Loss: 0.09606312091151874... Val Loss: 0.19233007729053497... val accuracy:0.9512038826942444.\n",
      "Epoch: 91/350... Loss: 0.08692407763252656... Val Loss: 0.17872842401266098... val accuracy:0.9601690471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 92/350... Loss: 0.1045884635920326... Val Loss: 0.19433850795030594... val accuracy:0.9515881240367889.\n",
      "Epoch: 93/350... Loss: 0.11973930305490892... Val Loss: 0.20546022802591324... val accuracy:0.9445440471172333.\n",
      "Epoch: 94/350... Loss: 0.08911869022995234... Val Loss: 0.19360718876123428... val accuracy:0.9441598355770111.\n",
      "Epoch: 95/350... Loss: 0.08895591149727504... Val Loss: 0.18905373848974705... val accuracy:0.9527407884597778.\n",
      "Epoch: 96/350... Loss: 0.08153852727264166... Val Loss: 0.19512209482491016... val accuracy:0.9449282884597778.\n",
      "Epoch: 97/350... Loss: 0.08678938262164593... Val Loss: 0.20984452962875366... val accuracy:0.9445440471172333.\n",
      "Epoch: 98/350... Loss: 0.07795040588825941... Val Loss: 0.21714164316654205... val accuracy:0.9437756240367889.\n",
      "Epoch: 99/350... Loss: 0.06551409124707182... Val Loss: 0.25629256665706635... val accuracy:0.9437756240367889.\n",
      "Epoch: 100/350... Loss: 0.11137535236775875... Val Loss: 0.27582039684057236... val accuracy:0.9273821711540222.\n",
      "Epoch: 101/350... Loss: 0.1411704427252213... Val Loss: 0.22493509203195572... val accuracy:0.9441598355770111.\n",
      "Epoch: 102/350... Loss: 0.14260800244907537... Val Loss: 0.2430509626865387... val accuracy:0.9273821711540222.\n",
      "Epoch: 103/350... Loss: 0.10411535079280536... Val Loss: 0.183003731071949... val accuracy:0.9515881240367889.\n",
      "Epoch: 104/350... Loss: 0.11711726399759452... Val Loss: 0.20197594910860062... val accuracy:0.9285348355770111.\n",
      "Epoch: 105/350... Loss: 0.09829833482702573... Val Loss: 0.18815207481384277... val accuracy:0.9441598355770111.\n",
      "Epoch: 106/350... Loss: 0.0811571404337883... Val Loss: 0.1669820249080658... val accuracy:0.9523565471172333.\n",
      "Val loss decreased...\n",
      "Epoch: 107/350... Loss: 0.0695372602591912... Val Loss: 0.17634963244199753... val accuracy:0.9523565471172333.\n",
      "Epoch: 108/350... Loss: 0.06600684796770413... Val Loss: 0.1756405010819435... val accuracy:0.9597848355770111.\n",
      "Epoch: 109/350... Loss: 0.07862326658020417... Val Loss: 0.1781509853899479... val accuracy:0.9515881240367889.\n",
      "Epoch: 110/350... Loss: 0.1099575941140453... Val Loss: 0.18786460906267166... val accuracy:0.9523565471172333.\n",
      "Epoch: 111/350... Loss: 0.11735602840781212... Val Loss: 0.2160002812743187... val accuracy:0.9601690471172333.\n",
      "Epoch: 112/350... Loss: 0.0987503935272495... Val Loss: 0.23689162731170654... val accuracy:0.9289190471172333.\n",
      "Epoch: 113/350... Loss: 0.09916502920289834... Val Loss: 0.2384754717350006... val accuracy:0.9355788826942444.\n",
      "Epoch: 114/350... Loss: 0.088839571379746... Val Loss: 0.2154771238565445... val accuracy:0.9433913826942444.\n",
      "Epoch: 115/350... Loss: 0.08907836768776178... Val Loss: 0.2143704518675804... val accuracy:0.9437756240367889.\n",
      "Epoch: 116/350... Loss: 0.07458925743897755... Val Loss: 0.18783989176154137... val accuracy:0.9441598355770111.\n",
      "Epoch: 117/350... Loss: 0.06861655755589406... Val Loss: 0.22578298300504684... val accuracy:0.9445440471172333.\n",
      "Epoch: 118/350... Loss: 0.07974241627380252... Val Loss: 0.1999908834695816... val accuracy:0.9519723355770111.\n",
      "Epoch: 119/350... Loss: 0.06293408169100682... Val Loss: 0.2114870697259903... val accuracy:0.9355788826942444.\n",
      "Epoch: 120/350... Loss: 0.06913824379444122... Val Loss: 0.20150760561227798... val accuracy:0.9437756240367889.\n",
      "Epoch: 121/350... Loss: 0.0618994307393829... Val Loss: 0.208473302423954... val accuracy:0.9519723355770111.\n",
      "Epoch: 122/350... Loss: 0.07053308251003425... Val Loss: 0.18559761345386505... val accuracy:0.9519723355770111.\n",
      "Epoch: 123/350... Loss: 0.06870999621848266... Val Loss: 0.23856526613235474... val accuracy:0.9355788826942444.\n",
      "Epoch: 124/350... Loss: 0.06178096278260151... Val Loss: 0.20577304810285568... val accuracy:0.9445440471172333.\n",
      "Epoch: 125/350... Loss: 0.06209666592379411... Val Loss: 0.1963156759738922... val accuracy:0.9519723355770111.\n",
      "Epoch: 126/350... Loss: 0.05030969250947237... Val Loss: 0.19834831357002258... val accuracy:0.9512038826942444.\n",
      "Epoch: 127/350... Loss: 0.0590525617202123... Val Loss: 0.21923309564590454... val accuracy:0.9515881240367889.\n",
      "Epoch: 128/350... Loss: 0.07003333543737729... Val Loss: 0.2515896260738373... val accuracy:0.9281506240367889.\n",
      "Epoch: 129/350... Loss: 0.06900016311556101... Val Loss: 0.2105223536491394... val accuracy:0.9679815471172333.\n",
      "Epoch: 130/350... Loss: 0.056313222429404654... Val Loss: 0.20341739803552628... val accuracy:0.9601690471172333.\n",
      "Epoch: 131/350... Loss: 0.06073428876698017... Val Loss: 0.21925251372158527... val accuracy:0.9512038826942444.\n",
      "Epoch: 132/350... Loss: 0.047532139966885247... Val Loss: 0.2179855927824974... val accuracy:0.9523565471172333.\n",
      "Epoch: 133/350... Loss: 0.05007003356392185... Val Loss: 0.20691867545247078... val accuracy:0.9601690471172333.\n",
      "Epoch: 134/350... Loss: 0.05977402782688538... Val Loss: 0.24773718416690826... val accuracy:0.9359631240367889.\n",
      "Epoch: 135/350... Loss: 0.0963458102196455... Val Loss: 0.16709765419363976... val accuracy:0.9679815471172333.\n",
      "Epoch: 136/350... Loss: 0.06442537407080333... Val Loss: 0.2149779787287116... val accuracy:0.9449282884597778.\n",
      "Epoch: 137/350... Loss: 0.08275917669137318... Val Loss: 0.18697708286345005... val accuracy:0.9597848355770111.\n",
      "Epoch: 138/350... Loss: 0.06748527040084203... Val Loss: 0.22389856725931168... val accuracy:0.9359631240367889.\n",
      "Epoch: 139/350... Loss: 0.05591137598579129... Val Loss: 0.18540222197771072... val accuracy:0.9519723355770111.\n",
      "Epoch: 140/350... Loss: 0.04533562374611696... Val Loss: 0.18776723183691502... val accuracy:0.9512038826942444.\n",
      "Epoch: 141/350... Loss: 0.047728983064492546... Val Loss: 0.18569564819335938... val accuracy:0.9515881240367889.\n",
      "Epoch: 142/350... Loss: 0.05231665354222059... Val Loss: 0.20134413242340088... val accuracy:0.9437756240367889.\n",
      "Epoch: 143/350... Loss: 0.14483886615683636... Val Loss: 0.194781094789505... val accuracy:0.9527407884597778.\n",
      "Epoch: 144/350... Loss: 0.06464289920404553... Val Loss: 0.19516994059085846... val accuracy:0.9597848355770111.\n",
      "Epoch: 145/350... Loss: 0.07089406282951434... Val Loss: 0.1829836070537567... val accuracy:0.9679815471172333.\n",
      "Epoch: 146/350... Loss: 0.06895577566077311... Val Loss: 0.2254461534321308... val accuracy:0.9675973355770111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147/350... Loss: 0.0673526655882597... Val Loss: 0.19911066442728043... val accuracy:0.9519723355770111.\n",
      "Epoch: 148/350... Loss: 0.056326418494184814... Val Loss: 0.18641866743564606... val accuracy:0.9523565471172333.\n",
      "Epoch: 149/350... Loss: 0.04808502675344547... Val Loss: 0.20313776284456253... val accuracy:0.9679815471172333.\n",
      "Epoch: 150/350... Loss: 0.04886594042181969... Val Loss: 0.20295150578022003... val accuracy:0.9761782884597778.\n",
      "Epoch: 151/350... Loss: 0.05023113529508313... Val Loss: 0.2032877467572689... val accuracy:0.9683657884597778.\n",
      "Epoch: 152/350... Loss: 0.047345198380450405... Val Loss: 0.2275511920452118... val accuracy:0.9601690471172333.\n",
      "Epoch: 153/350... Loss: 0.06106204011787971... Val Loss: 0.3425951898097992... val accuracy:0.9047131240367889.\n",
      "Epoch: 154/350... Loss: 0.13641112049420676... Val Loss: 0.3580973148345947... val accuracy:0.9039446711540222.\n",
      "Epoch: 155/350... Loss: 0.13688865397125483... Val Loss: 0.28743644058704376... val accuracy:0.9195696711540222.\n",
      "Epoch: 156/350... Loss: 0.08250080483655135... Val Loss: 0.22712574899196625... val accuracy:0.9441598355770111.\n",
      "Epoch: 157/350... Loss: 0.06434151871750753... Val Loss: 0.22250888869166374... val accuracy:0.9512038826942444.\n",
      "Epoch: 158/350... Loss: 0.05461184245844682... Val Loss: 0.1977907232940197... val accuracy:0.9512038826942444.\n",
      "Epoch: 159/350... Loss: 0.050554574467241764... Val Loss: 0.20542585477232933... val accuracy:0.9597848355770111.\n",
      "Epoch: 160/350... Loss: 0.045590438259144626... Val Loss: 0.1844363585114479... val accuracy:0.9605532884597778.\n",
      "Epoch: 161/350... Loss: 0.043246559177835785... Val Loss: 0.21333392709493637... val accuracy:0.9515881240367889.\n",
      "Epoch: 162/350... Loss: 0.03845230055352052... Val Loss: 0.1889602690935135... val accuracy:0.9601690471172333.\n",
      "Epoch: 163/350... Loss: 0.035052841839691005... Val Loss: 0.19521379843354225... val accuracy:0.9597848355770111.\n",
      "Epoch: 164/350... Loss: 0.03283509984612465... Val Loss: 0.20065279304981232... val accuracy:0.9597848355770111.\n",
      "Epoch: 165/350... Loss: 0.02965731220319867... Val Loss: 0.20444104075431824... val accuracy:0.9601690471172333.\n",
      "Epoch: 166/350... Loss: 0.032668824307620525... Val Loss: 0.21111822873353958... val accuracy:0.9605532884597778.\n",
      "Epoch: 167/350... Loss: 0.04364323988556862... Val Loss: 0.20766305178403854... val accuracy:0.9605532884597778.\n",
      "Epoch: 168/350... Loss: 0.04824397712945938... Val Loss: 0.1936328075826168... val accuracy:0.9675973355770111.\n",
      "Epoch: 169/350... Loss: 0.04239898594096303... Val Loss: 0.1939130611717701... val accuracy:0.9601690471172333.\n",
      "Epoch: 170/350... Loss: 0.03237829823046923... Val Loss: 0.19120900705456734... val accuracy:0.9512038826942444.\n",
      "Epoch: 171/350... Loss: 0.0376791295905908... Val Loss: 0.2032956648617983... val accuracy:0.9605532884597778.\n",
      "Epoch: 172/350... Loss: 0.03545731663083037... Val Loss: 0.1856272593140602... val accuracy:0.9757940471172333.\n",
      "Epoch: 173/350... Loss: 0.030322116722042363... Val Loss: 0.19963188096880913... val accuracy:0.9597848355770111.\n",
      "Epoch: 174/350... Loss: 0.03125890468557676... Val Loss: 0.20712143927812576... val accuracy:0.9675973355770111.\n",
      "Epoch: 175/350... Loss: 0.029781205269197624... Val Loss: 0.207302026450634... val accuracy:0.9761782884597778.\n",
      "Epoch: 176/350... Loss: 0.03186114535977443... Val Loss: 0.22756740637123585... val accuracy:0.9515881240367889.\n",
      "Epoch: 177/350... Loss: 0.03290903389764329... Val Loss: 0.2032202184200287... val accuracy:0.9679815471172333.\n",
      "Epoch: 178/350... Loss: 0.028541374020278454... Val Loss: 0.21018416434526443... val accuracy:0.9683657884597778.\n",
      "Epoch: 179/350... Loss: 0.028258152926961582... Val Loss: 0.20564360544085503... val accuracy:0.9679815471172333.\n",
      "Epoch: 180/350... Loss: 0.023639196219543617... Val Loss: 0.21235302090644836... val accuracy:0.9679815471172333.\n",
      "Epoch: 181/350... Loss: 0.02584724221378565... Val Loss: 0.21539901196956635... val accuracy:0.9605532884597778.\n",
      "Epoch: 182/350... Loss: 0.037373377941548824... Val Loss: 0.20922069251537323... val accuracy:0.9601690471172333.\n",
      "Epoch: 183/350... Loss: 0.03467084529499213... Val Loss: 0.22454191744327545... val accuracy:0.9683657884597778.\n",
      "Epoch: 184/350... Loss: 0.0658451368411382... Val Loss: 0.2509167566895485... val accuracy:0.9515881240367889.\n",
      "Epoch: 185/350... Loss: 0.04213233230014642... Val Loss: 0.24555806815624237... val accuracy:0.9519723355770111.\n",
      "Epoch: 186/350... Loss: 0.04882975450406472... Val Loss: 0.2638337090611458... val accuracy:0.9351946711540222.\n",
      "Epoch: 187/350... Loss: 0.058321481881042324... Val Loss: 0.21660296991467476... val accuracy:0.9515881240367889.\n",
      "Epoch: 188/350... Loss: 0.05510852734247843... Val Loss: 0.24165796488523483... val accuracy:0.9515881240367889.\n",
      "Epoch: 189/350... Loss: 0.05407466273754835... Val Loss: 0.2216818928718567... val accuracy:0.9508196711540222.\n",
      "Epoch: 190/350... Loss: 0.04645448814456662... Val Loss: 0.19020729139447212... val accuracy:0.9433913826942444.\n",
      "Epoch: 191/350... Loss: 0.042766684045394264... Val Loss: 0.19312097877264023... val accuracy:0.9449282884597778.\n",
      "Epoch: 192/350... Loss: 0.0303689722592632... Val Loss: 0.22692986577749252... val accuracy:0.9441598355770111.\n",
      "Epoch: 193/350... Loss: 0.03816435392946005... Val Loss: 0.199203260242939... val accuracy:0.9523565471172333.\n",
      "Epoch: 194/350... Loss: 0.035810950522621475... Val Loss: 0.19104455586057156... val accuracy:0.953125.\n",
      "Epoch: 195/350... Loss: 0.04512652071813742... Val Loss: 0.21041062846779823... val accuracy:0.9371157884597778.\n",
      "Epoch: 196/350... Loss: 0.0478636771440506... Val Loss: 0.24530044198036194... val accuracy:0.9605532884597778.\n",
      "Epoch: 197/350... Loss: 0.03802168920325736... Val Loss: 0.21290974458679557... val accuracy:0.96875.\n",
      "Epoch: 198/350... Loss: 0.028486226064463455... Val Loss: 0.2112572118639946... val accuracy:0.9594006240367889.\n",
      "Epoch: 199/350... Loss: 0.02691565128043294... Val Loss: 0.21612612903118134... val accuracy:0.9441598355770111.\n",
      "Epoch: 200/350... Loss: 0.028941697751482327... Val Loss: 0.22061452269554138... val accuracy:0.9675973355770111.\n",
      "Epoch: 201/350... Loss: 0.03479944014300903... Val Loss: 0.2179494947195053... val accuracy:0.9597848355770111.\n",
      "Epoch: 202/350... Loss: 0.038371337888141475... Val Loss: 0.21148671954870224... val accuracy:0.9594006240367889.\n",
      "Epoch: 203/350... Loss: 0.027253782958723605... Val Loss: 0.23811539262533188... val accuracy:0.9597848355770111.\n",
      "Epoch: 204/350... Loss: 0.0365072979281346... Val Loss: 0.2104063332080841... val accuracy:0.9597848355770111.\n",
      "Epoch: 205/350... Loss: 0.028519929726220045... Val Loss: 0.21285977121442556... val accuracy:0.9609375.\n",
      "Epoch: 206/350... Loss: 0.030074693573017914... Val Loss: 0.2357005663216114... val accuracy:0.9605532884597778.\n",
      "Epoch: 207/350... Loss: 0.03230681084096432... Val Loss: 0.22407633066177368... val accuracy:0.9601690471172333.\n",
      "Epoch: 208/350... Loss: 0.027317661171158154... Val Loss: 0.22717271372675896... val accuracy:0.9605532884597778.\n",
      "Epoch: 209/350... Loss: 0.030129801171521347... Val Loss: 0.23438700288534164... val accuracy:0.9597848355770111.\n",
      "Epoch: 210/350... Loss: 0.023056515182058018... Val Loss: 0.21683892607688904... val accuracy:0.9605532884597778.\n",
      "Epoch: 211/350... Loss: 0.022713869732494157... Val Loss: 0.2322819799883291... val accuracy:0.9609375.\n",
      "Epoch: 212/350... Loss: 0.024487909860908985... Val Loss: 0.24981412291526794... val accuracy:0.9515881240367889.\n",
      "Epoch: 213/350... Loss: 0.035816735277573265... Val Loss: 0.2392931031063199... val accuracy:0.9527407884597778.\n",
      "Epoch: 214/350... Loss: 0.02782807545736432... Val Loss: 0.2268062625080347... val accuracy:0.9601690471172333.\n",
      "Epoch: 215/350... Loss: 0.029075542464852333... Val Loss: 0.22770077362656593... val accuracy:0.9675973355770111.\n",
      "Epoch: 216/350... Loss: 0.02907836188872655... Val Loss: 0.2359101101756096... val accuracy:0.9605532884597778.\n",
      "Epoch: 217/350... Loss: 0.03281239947925011... Val Loss: 0.2637679725885391... val accuracy:0.9605532884597778.\n",
      "Epoch: 218/350... Loss: 0.027417874429374933... Val Loss: 0.2843364477157593... val accuracy:0.9519723355770111.\n",
      "Epoch: 219/350... Loss: 0.02596970632051428... Val Loss: 0.2657194184139371... val accuracy:0.96875.\n",
      "Epoch: 220/350... Loss: 0.03292877941081921... Val Loss: 0.28773900866508484... val accuracy:0.9515881240367889.\n",
      "Epoch: 221/350... Loss: 0.03906741924583912... Val Loss: 0.281533420085907... val accuracy:0.9601690471172333.\n",
      "Epoch: 222/350... Loss: 0.06280308342926826... Val Loss: 0.25858965516090393... val accuracy:0.9515881240367889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 223/350... Loss: 0.043234484270215034... Val Loss: 0.2770227640867233... val accuracy:0.9601690471172333.\n",
      "Epoch: 224/350... Loss: 0.04135009304930767... Val Loss: 0.2549222335219383... val accuracy:0.9508196711540222.\n",
      "Epoch: 225/350... Loss: 0.043087694173057876... Val Loss: 0.25668516010046005... val accuracy:0.9445440471172333.\n",
      "Epoch: 226/350... Loss: 0.04657962545752525... Val Loss: 0.27850648760795593... val accuracy:0.9523565471172333.\n",
      "Epoch: 227/350... Loss: 0.04739487667878469... Val Loss: 0.18469989486038685... val accuracy:0.9683657884597778.\n",
      "Epoch: 228/350... Loss: 0.043886425284047924... Val Loss: 0.22796014696359634... val accuracy:0.9515881240367889.\n",
      "Epoch: 229/350... Loss: 0.034153403559078775... Val Loss: 0.24083665758371353... val accuracy:0.9523565471172333.\n",
      "Epoch: 230/350... Loss: 0.03844438834736744... Val Loss: 0.25363995507359505... val accuracy:0.9437756240367889.\n",
      "Epoch: 231/350... Loss: 0.037404067271078624... Val Loss: 0.2365409431513399... val accuracy:0.9453125.\n",
      "Epoch: 232/350... Loss: 0.04130286901878814... Val Loss: 0.21043270826339722... val accuracy:0.9523565471172333.\n",
      "Epoch: 233/350... Loss: 0.023383888105551403... Val Loss: 0.20322579145431519... val accuracy:0.9605532884597778.\n",
      "Epoch: 234/350... Loss: 0.01969672824877004... Val Loss: 0.22520438209176064... val accuracy:0.9683657884597778.\n",
      "Epoch: 235/350... Loss: 0.020711854721109074... Val Loss: 0.22524331510066986... val accuracy:0.9515881240367889.\n",
      "Epoch: 236/350... Loss: 0.021015704958699644... Val Loss: 0.25468122959136963... val accuracy:0.9512038826942444.\n",
      "Epoch: 237/350... Loss: 0.029752176875869434... Val Loss: 0.23111790150869638... val accuracy:0.9609375.\n",
      "Epoch: 238/350... Loss: 0.02709092149355759... Val Loss: 0.2751473933458328... val accuracy:0.9597848355770111.\n",
      "Epoch: 239/350... Loss: 0.028461964956174295... Val Loss: 0.26396703720092773... val accuracy:0.9519723355770111.\n",
      "Epoch: 240/350... Loss: 0.025406384937620412... Val Loss: 0.23813531547784805... val accuracy:0.9601690471172333.\n",
      "Epoch: 241/350... Loss: 0.03183391162504753... Val Loss: 0.2257848009467125... val accuracy:0.9523565471172333.\n",
      "Epoch: 242/350... Loss: 0.034052926348522305... Val Loss: 0.36157019436359406... val accuracy:0.9363473355770111.\n",
      "Epoch: 243/350... Loss: 0.058368414950867496... Val Loss: 0.2707504704594612... val accuracy:0.9512038826942444.\n",
      "Epoch: 244/350... Loss: 0.06844126743574937... Val Loss: 0.3518868237733841... val accuracy:0.9047131240367889.\n",
      "Epoch: 245/350... Loss: 0.050792086559037365... Val Loss: 0.2350318506360054... val accuracy:0.9445440471172333.\n",
      "Epoch: 246/350... Loss: 0.04175151411133508... Val Loss: 0.25560872070491314... val accuracy:0.9512038826942444.\n",
      "Epoch: 247/350... Loss: 0.03406258951872587... Val Loss: 0.2621198445558548... val accuracy:0.9515881240367889.\n",
      "Epoch: 248/350... Loss: 0.05835205875337124... Val Loss: 0.23041556030511856... val accuracy:0.9512038826942444.\n",
      "Epoch: 249/350... Loss: 0.051838248036801815... Val Loss: 0.21972226351499557... val accuracy:0.9597848355770111.\n",
      "Epoch: 250/350... Loss: 0.0396822157005469... Val Loss: 0.21296381205320358... val accuracy:0.9441598355770111.\n",
      "Epoch: 251/350... Loss: 0.07263055630028248... Val Loss: 0.21980036795139313... val accuracy:0.9594006240367889.\n",
      "Epoch: 252/350... Loss: 0.1076377152154843... Val Loss: 0.2714940309524536... val accuracy:0.9359631240367889.\n",
      "Epoch: 253/350... Loss: 0.09910915233194828... Val Loss: 0.18545196391642094... val accuracy:0.9683657884597778.\n",
      "Epoch: 254/350... Loss: 0.048451962880790234... Val Loss: 0.2080945074558258... val accuracy:0.9437756240367889.\n",
      "Epoch: 255/350... Loss: 0.04386819045369824... Val Loss: 0.2293218895792961... val accuracy:0.9523565471172333.\n",
      "Epoch: 256/350... Loss: 0.040388581808656454... Val Loss: 0.21000395715236664... val accuracy:0.9519723355770111.\n",
      "Epoch: 257/350... Loss: 0.029525681010757882... Val Loss: 0.22518138587474823... val accuracy:0.9523565471172333.\n",
      "Epoch: 258/350... Loss: 0.05162081805368265... Val Loss: 0.21128223463892937... val accuracy:0.96875.\n",
      "Epoch: 259/350... Loss: 0.057385451470812164... Val Loss: 0.2116204984486103... val accuracy:0.9675973355770111.\n",
      "Epoch: 260/350... Loss: 0.0419301421691974... Val Loss: 0.22084541618824005... val accuracy:0.9515881240367889.\n",
      "Epoch: 261/350... Loss: 0.04391885486741861... Val Loss: 0.22938328236341476... val accuracy:0.9433913826942444.\n",
      "Epoch: 262/350... Loss: 0.0544091130917271... Val Loss: 0.2513381987810135... val accuracy:0.9515881240367889.\n",
      "Epoch: 263/350... Loss: 0.06876824734111626... Val Loss: 0.2412901669740677... val accuracy:0.9515881240367889.\n",
      "Epoch: 264/350... Loss: 0.12834325339645147... Val Loss: 0.21647726371884346... val accuracy:0.9512038826942444.\n",
      "Epoch: 265/350... Loss: 0.07110454825063546... Val Loss: 0.25056519359350204... val accuracy:0.9519723355770111.\n",
      "Epoch: 266/350... Loss: 0.04213783610612154... Val Loss: 0.23428434133529663... val accuracy:0.9437756240367889.\n",
      "Epoch: 267/350... Loss: 0.03642434657861789... Val Loss: 0.27152200788259506... val accuracy:0.9433913826942444.\n",
      "Epoch: 268/350... Loss: 0.027101191071172554... Val Loss: 0.260199673473835... val accuracy:0.9519723355770111.\n",
      "Epoch: 269/350... Loss: 0.042169149266555905... Val Loss: 0.26649123430252075... val accuracy:0.9523565471172333.\n",
      "Epoch: 270/350... Loss: 0.0327832850938042... Val Loss: 0.23823826014995575... val accuracy:0.9683657884597778.\n",
      "Epoch: 271/350... Loss: 0.03199471067637205... Val Loss: 0.2588583081960678... val accuracy:0.9597848355770111.\n",
      "Epoch: 272/350... Loss: 0.030522646692891914... Val Loss: 0.2816444933414459... val accuracy:0.9601690471172333.\n",
      "Epoch: 273/350... Loss: 0.032345191886027656... Val Loss: 0.2891894578933716... val accuracy:0.9601690471172333.\n",
      "Epoch: 274/350... Loss: 0.034328228794038296... Val Loss: 0.265454038977623... val accuracy:0.9519723355770111.\n",
      "Epoch: 275/350... Loss: 0.03125038735258082... Val Loss: 0.2579069286584854... val accuracy:0.9605532884597778.\n",
      "Epoch: 276/350... Loss: 0.024917756226689864... Val Loss: 0.27189165353775024... val accuracy:0.9679815471172333.\n",
      "Epoch: 277/350... Loss: 0.024796618109879393... Val Loss: 0.2800658866763115... val accuracy:0.9675973355770111.\n",
      "Epoch: 278/350... Loss: 0.021496582504672308... Val Loss: 0.2675893306732178... val accuracy:0.9597848355770111.\n",
      "Epoch: 279/350... Loss: 0.018452595143268507... Val Loss: 0.2712313272058964... val accuracy:0.9675973355770111.\n",
      "Epoch: 280/350... Loss: 0.02205276396125555... Val Loss: 0.26778915524482727... val accuracy:0.9683657884597778.\n",
      "Epoch: 281/350... Loss: 0.02632117023070653... Val Loss: 0.25734466686844826... val accuracy:0.96875.\n",
      "Epoch: 282/350... Loss: 0.024697154760360718... Val Loss: 0.2736594043672085... val accuracy:0.9601690471172333.\n",
      "Epoch: 283/350... Loss: 0.0254055857755399... Val Loss: 0.2889218330383301... val accuracy:0.9597848355770111.\n",
      "Epoch: 284/350... Loss: 0.0219900196728607... Val Loss: 0.277821883559227... val accuracy:0.9675973355770111.\n",
      "Epoch: 285/350... Loss: 0.018312913404467206... Val Loss: 0.26186974346637726... val accuracy:0.9679815471172333.\n",
      "Epoch: 286/350... Loss: 0.02482226040835182... Val Loss: 0.2791244462132454... val accuracy:0.9679815471172333.\n",
      "Epoch: 287/350... Loss: 0.035007069197793804... Val Loss: 0.2682691919617355... val accuracy:0.9609375.\n",
      "Epoch: 288/350... Loss: 0.03466051739330093... Val Loss: 0.25920625030994415... val accuracy:0.9601690471172333.\n",
      "Epoch: 289/350... Loss: 0.03964483536158999... Val Loss: 0.2929067462682724... val accuracy:0.9597848355770111.\n",
      "Epoch: 290/350... Loss: 0.04314908944070339... Val Loss: 0.24004279356449842... val accuracy:0.9609375.\n",
      "Epoch: 291/350... Loss: 0.034520523312191166... Val Loss: 0.2489024791866541... val accuracy:0.9527407884597778.\n",
      "Epoch: 292/350... Loss: 0.04494889018436273... Val Loss: 0.24053744971752167... val accuracy:0.9605532884597778.\n",
      "Epoch: 293/350... Loss: 0.040222709998488426... Val Loss: 0.2624933123588562... val accuracy:0.9601690471172333.\n",
      "Epoch: 294/350... Loss: 0.03695323256154855... Val Loss: 0.2800431326031685... val accuracy:0.9601690471172333.\n",
      "Epoch: 295/350... Loss: 0.037903910813232265... Val Loss: 0.24145996570587158... val accuracy:0.9597848355770111.\n",
      "Epoch: 296/350... Loss: 0.029775635649760563... Val Loss: 0.24472129344940186... val accuracy:0.9679815471172333.\n",
      "Epoch: 297/350... Loss: 0.03660453266153733... Val Loss: 0.2588980495929718... val accuracy:0.9601690471172333.\n",
      "Epoch: 298/350... Loss: 0.04616217718770107... Val Loss: 0.248205728828907... val accuracy:0.9597848355770111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/350... Loss: 0.03528486688931783... Val Loss: 0.2562623471021652... val accuracy:0.9523565471172333.\n",
      "Epoch: 300/350... Loss: 0.040502025124927364... Val Loss: 0.2358592003583908... val accuracy:0.9527407884597778.\n",
      "Epoch: 301/350... Loss: 0.022580476788183052... Val Loss: 0.17949308082461357... val accuracy:0.9761782884597778.\n",
      "Epoch: 302/350... Loss: 0.021523458572725456... Val Loss: 0.18683570623397827... val accuracy:0.9683657884597778.\n",
      "Epoch: 303/350... Loss: 0.019335536596675713... Val Loss: 0.20041901618242264... val accuracy:0.9601690471172333.\n",
      "Epoch: 304/350... Loss: 0.020817310161267717... Val Loss: 0.19262031465768814... val accuracy:0.9601690471172333.\n",
      "Epoch: 305/350... Loss: 0.016675428642580908... Val Loss: 0.20921768248081207... val accuracy:0.9594006240367889.\n",
      "Epoch: 306/350... Loss: 0.014208508810649315... Val Loss: 0.19757364690303802... val accuracy:0.9679815471172333.\n",
      "Epoch: 307/350... Loss: 0.01273596721390883... Val Loss: 0.19775736145675182... val accuracy:0.9683657884597778.\n",
      "Epoch: 308/350... Loss: 0.014172122348099947... Val Loss: 0.21756969392299652... val accuracy:0.9597848355770111.\n",
      "Epoch: 309/350... Loss: 0.01426854458016654... Val Loss: 0.2052246294915676... val accuracy:0.9679815471172333.\n",
      "Epoch: 310/350... Loss: 0.018210400206347305... Val Loss: 0.21309113502502441... val accuracy:0.9675973355770111.\n",
      "Epoch: 311/350... Loss: 0.018320022306094568... Val Loss: 0.2292177826166153... val accuracy:0.9597848355770111.\n",
      "Epoch: 312/350... Loss: 0.01499510471088191... Val Loss: 0.22388672828674316... val accuracy:0.9601690471172333.\n",
      "Epoch: 313/350... Loss: 0.01717642725755771... Val Loss: 0.21172833442687988... val accuracy:0.9757940471172333.\n",
      "Epoch: 314/350... Loss: 0.019647798656175535... Val Loss: 0.21375036984682083... val accuracy:0.9683657884597778.\n",
      "Epoch: 315/350... Loss: 0.029898458160459995... Val Loss: 0.2744068019092083... val accuracy:0.9605532884597778.\n",
      "Epoch: 316/350... Loss: 0.055647593612472214... Val Loss: 0.2331099808216095... val accuracy:0.9515881240367889.\n",
      "Epoch: 317/350... Loss: 0.034281769301742315... Val Loss: 0.20548640191555023... val accuracy:0.9683657884597778.\n",
      "Epoch: 318/350... Loss: 0.025011003172645967... Val Loss: 0.2060750499367714... val accuracy:0.9761782884597778.\n",
      "Epoch: 319/350... Loss: 0.020389992743730545... Val Loss: 0.21045104414224625... val accuracy:0.9683657884597778.\n",
      "Epoch: 320/350... Loss: 0.022203642409294844... Val Loss: 0.23461543768644333... val accuracy:0.9675973355770111.\n",
      "Epoch: 321/350... Loss: 0.022171663644257933... Val Loss: 0.23465538024902344... val accuracy:0.9672131240367889.\n",
      "Epoch: 322/350... Loss: 0.018809538645048935... Val Loss: 0.22574321925640106... val accuracy:0.9757940471172333.\n",
      "Epoch: 323/350... Loss: 0.02649063679079215... Val Loss: 0.23360924422740936... val accuracy:0.9597848355770111.\n",
      "Epoch: 324/350... Loss: 0.020192106099178393... Val Loss: 0.23258251510560513... val accuracy:0.9754098355770111.\n",
      "Epoch: 325/350... Loss: 0.017920626016954582... Val Loss: 0.23014004528522491... val accuracy:0.9594006240367889.\n",
      "Epoch: 326/350... Loss: 0.019758381531573832... Val Loss: 0.24065563455224037... val accuracy:0.9590163826942444.\n",
      "Epoch: 327/350... Loss: 0.022067326547888417... Val Loss: 0.22813630849123... val accuracy:0.9679815471172333.\n",
      "Epoch: 328/350... Loss: 0.018368819806103904... Val Loss: 0.25841687619686127... val accuracy:0.9512038826942444.\n",
      "Epoch: 329/350... Loss: 0.024911010016997654... Val Loss: 0.23024434968829155... val accuracy:0.9605532884597778.\n",
      "Epoch: 330/350... Loss: 0.027850870896751683... Val Loss: 0.259026363492012... val accuracy:0.9523565471172333.\n",
      "Epoch: 331/350... Loss: 0.02935779932886362... Val Loss: 0.2565681040287018... val accuracy:0.9597848355770111.\n",
      "Epoch: 332/350... Loss: 0.020538885456820328... Val Loss: 0.2480858564376831... val accuracy:0.9597848355770111.\n",
      "Epoch: 333/350... Loss: 0.017987067966411512... Val Loss: 0.2473350688815117... val accuracy:0.9594006240367889.\n",
      "Epoch: 334/350... Loss: 0.029616802673748072... Val Loss: 0.27157869935035706... val accuracy:0.9523565471172333.\n",
      "Epoch: 335/350... Loss: 0.038334358289527394... Val Loss: 0.3197821229696274... val accuracy:0.9437756240367889.\n",
      "Epoch: 336/350... Loss: 0.08756045531481504... Val Loss: 0.2346731200814247... val accuracy:0.9523565471172333.\n",
      "Epoch: 337/350... Loss: 0.09035775267208616... Val Loss: 0.33458421379327774... val accuracy:0.9281506240367889.\n",
      "Epoch: 338/350... Loss: 0.09809659949193399... Val Loss: 0.30026696622371674... val accuracy:0.9277663826942444.\n",
      "Epoch: 339/350... Loss: 0.08466458972543478... Val Loss: 0.22731590270996094... val accuracy:0.9679815471172333.\n",
      "Epoch: 340/350... Loss: 0.07225486015280087... Val Loss: 0.2542489171028137... val accuracy:0.9363473355770111.\n",
      "Epoch: 341/350... Loss: 0.06239918898791075... Val Loss: 0.23685332387685776... val accuracy:0.9523565471172333.\n",
      "Epoch: 342/350... Loss: 0.038206323981285095... Val Loss: 0.23385032638907433... val accuracy:0.9519723355770111.\n",
      "Epoch: 343/350... Loss: 0.03462057622770468... Val Loss: 0.26345038414001465... val accuracy:0.9597848355770111.\n",
      "Epoch: 344/350... Loss: 0.042717487861712776... Val Loss: 0.226431205868721... val accuracy:0.9519723355770111.\n",
      "Epoch: 345/350... Loss: 0.04097571503371... Val Loss: 0.23058642446994781... val accuracy:0.9519723355770111.\n",
      "Epoch: 346/350... Loss: 0.02655183314345777... Val Loss: 0.24716170132160187... val accuracy:0.9512038826942444.\n",
      "Epoch: 347/350... Loss: 0.029778423098226387... Val Loss: 0.2422717660665512... val accuracy:0.9527407884597778.\n",
      "Epoch: 348/350... Loss: 0.02155167912133038... Val Loss: 0.2504376769065857... val accuracy:0.9594006240367889.\n",
      "Epoch: 349/350... Loss: 0.0203431472958376... Val Loss: 0.25120747089385986... val accuracy:0.9594006240367889.\n",
      "Epoch: 350/350... Loss: 0.0170453869116803... Val Loss: 0.2608181908726692... val accuracy:0.9523565471172333.\n",
      "min loss 0.1669820249080658\n",
      "Training time is: 20.16972589492798 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b4026f9e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = LSTM(1,3,64,2) #512,2 0.983  256,2 0.983 ,64 ,2 0.984,32,2,0.983,256,4.0.983\n",
    "from time import time\n",
    "if train_on_gpu:\n",
    "    net.cuda()\n",
    "start = time()\n",
    "epochs = 350\n",
    "accuracy = train(net,epochs,train_loader,valid_loader,clip=5,lr=0.0128)\n",
    "print('Training time is:',time()-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FPX5wPHPQzjCpYAElEsOaSsenILi/VMUFcVbvPGiVqFotRWsorXW2lpbL6qlVfEsnlisVBSrRVtUgoKAgCBgCRWN3ARCDp7fH9+ZzGTZJJtkJ7vJPu/Xa187851jn51s5pnv9zuHqCrGGGMMQKNUB2CMMSZ9WFIwxhhTxpKCMcaYMpYUjDHGlLGkYIwxpowlBWOMMWUsKRiTwUTkRBFZk+o4TPqwpGDSloi8JyKbRKRZqmOJiohsD712i8jO0PjFqY7PZB5LCiYtiUh34GhAgTPq8HMb19VnAahqK/8F/Bc4PVT2XKrjM5nHkoJJV5cBHwJTgcv9QhFpLiL3i8hXIrJFRD4QkebetKNE5D8isllE1orIaK/8PRG5OrSO0SLyQWhcReR6EVkBrPDKHvTWsVVE5ovI0aH5s0TkVhH5UkS2edO7ishkEbk//CVEZIaI3FjTjSAid4vICyLyVxHZBlwiIo1Cn/+diEwTkbbe/Ad43+cyEckTkXwRmRBaXwsRecargS0BBtY0NtMwWVIw6eoy4DnvdbKIdPTKf4fbkQ0F2gE/A3aLyP7AP4CHgRygH7CgGp93JjAE6OONz/PW0Q54HnhJRLK9aT8BLgROBfYCrgR2AE8BF4pIIwARaQ+c6C1fG2d569gbeAG4ETgNOAboAmwHHopZZihwAHAy8AsR6e2V3wV0BXp68V+OMWGqai97pdULOAooBtp748twO8JGwE6gb5xlJgLTK1jfe8DVofHRwAehcQX+r4qYNvmfCywHRlYw31JgmDc8FphZje+9Bjgxpuxu4J8xZSuAY0PjXYFCb/sc4H2ffUPTPwHO9Yb/G/4M4DpgTar/5vZKn5fVFEw6uhx4S1W/88af98raA9nAl3GW6VpBeaLWhkdE5GYRWeo1UW3GHaW3T+CzngIu8YYvAZ6pRUxxYwO6Aa97zWSbgUVeeQd/BlVdH5p/B9DKG94vZn1fJSE+04BYp5VJK17/wPlAloj4O7ZmQBvcDq0Q6AUsjFl0LTC4gtUWAC1C4/vGmafsdsFe/8HPgBOAJaq6W0Q2ARL6rF7A4jjreRZYLCJ9gQOB1yqIqTpib2WcB1ykqh/FzigiB1SxrvW4pLbcG+9W+/BMQ2I1BZNuzgRKcW37/bzXgcD7uH6GJ4Dfi0gnr8P3CO+U1eeAE0XkfBFpLCL7iEg/b50LgLO9TtYDgKuqiKE1UALkA41FZBKu78D3F+CXItJbnENFZB8AVc3D9Uc8A7yiqjtru0HieAy4R0S6AYhIBxFJ9AytF4FbRaSNt/zYCOIz9ZglBZNuLgeeVNX/qup6/wU8AlwMTMA1l8wDNgK/ARqp6n9xHac3eeULgL7eOv8AFAHf4Jp39jjVM8Ys4E3gC1zzSiHlm1x+j9u5vgVsBR4HmoemPwUcQnKajuL5vRffO94ZSf8BDktw2TuAr3H9F/8Ano4iQFN/iao9ZMeYZBKRY3DNSPur/YOZesZqCsYkkYg0AcYDf7GEYOojSwrGJImIHAhsxnWIPxAq7xZzO4vwyzp6TVqx5iNjjDFlrKZgjDGmTL27TqF9+/bavXv3VIdhjDH1yvz5879T1Zyq5ossKYjIE8AI4FtVPTjOdAEexJ1GuAMYraqfVLXe7t27k5ubm+xwjTGmQRORhK5ej7L5aCowvJLppwC9vdcY4NEIYzHGGJOAyJKCqs7BXURUkZHA0+p8CLQRkf2iiscYY0zVUtnR3JnyV4nmeWV7EJExIpIrIrn5+fl1EpwxxmSienH2kapOUdVBqjooJ6fKfhJjjDE1lMqksA53t0ZfF6/MGGNMiqQyKcwALvPuMnk4sEVVv05hPMYYk/GiPCX1r8BxQHsRycPdnbEJgKo+BszEnY66EndK6hVRxWKMMSYxkSUFVb2wiukKXB/V5xsTz5o18PHHcP75tV9XcTHMng3Dh0NuLuzaBUcdVfv1mrrz7rvQpg3071/5fIWF8N57cPLJIN6jlqZNg6FDoVs32LABli6FXr2gUSPo2LHS1aW1etHRbEyy3HwzXHABLF9e9bxVef55OPVUmDfPrfNHP6r9Ok3duuoquPhiqOoWcE8/DaecAu+848YXLYILL3S/J4Cjj3avU05x66vPLCmYemHdOtgYc9XL1q3w3/9WvtyqVfDRR1BaCt9+C3/7myufMqVmcWzdCjt2uOEPP3Tv994Lq1e7z1q0yO1Apk2D//zHTV+xonpJ6KuvYPp0N7x5MxQVVT/Gnd7z3nbsgKeeir/TKyoKdnJhu3fDm29WvaOszFdfuSNn344d8OijsHJl1csuXAh5eeXLNm6EOXPc9/rf/+DFF+Hhh9132LHDJeZ33nHbq6p1+9+rqCiI84MPgjinT3d/29Wr3W9HNfhbP/KIe3/sMfc+fTq88UbwXRcuDH5vixe7bVmVjRvh63TqTVXVevUaOHCgmszj/jXLl40fr9q1a8XLFBaqdujglvv1r1UffdQNDxig2q6d6s6d1YuhpES1Tx/V005z4wMGBHFV9Hr//fixV+ass9z8a9e696OOql6MP/iB6umnu/E//cmtY+7cPeedMsVNW7y4fPnUqa581qzEPzfWmWeqHnpoMP6Xv7h1iqhu2VLxcrt3x99ep5/uygYPVt1772CeqVNVzzknGD/rrIrX/e67bp7HH3fjy5cHy118sSubMMGNN2+uuu++bvjWW1UPPtgNN2qkunq1ak6O6tChqq1bx/+7P/aYe3/kkaq31YUXqh5+eNXz1RaQqwnsY1O+k6/uy5JC3du0SbW4uGbLlpa695ISt56a8v/Zlixx499953bOoLp5c/xlpk0Lljv1VNUrrlBt31717bdd2bPPxo934ULVb79V/fprtwP45hvVpUtVH3wwWN/8+aqNGwfj3/9+MPzLX6p+9plq27aqe+0VlO/aVfX3/PrrYL133hks+913qlu3qq5cqfrvf6t+8IHqnDmqy5a58ddfdzvUGTOCZR55xH1ncLFv2eLWUVjoPuuqq4Ida9jhh7vyX/3KJabZs1WLilQ3bAj+nvHs3h0M9+unmp0dlP3oR0Fc771X8Tr8RAiqH37otv9XX7mdcXin+49/qPburdq9uxu/4grVa691See111QXLVL95z9V8/Pd5y1erHr22W7e/v1VCwpUZ84MxsFtzw4dyicdkWD4iitcHBdf7MYfftj9Tt58U/WVV1T32y+Y1/+7X3qp++3s3q26fXv5beQ74gjVffYJxivbxrVhScEkRUGB25FOnFj9ZVeuVG3Vyu2wzjzT/dri/VNUpaQk+GcbP171gQfccPv2Qfkll+y53HHHqe6/v/vHzMlxR3unnOL+6bp3D46mw667zq2vb193tBh7BNirl2qzZsGOxH9/4YVgnuXL3bp+/vPyy37ySdXf1T+y79TJ7VT9ZWN3ivFeb72lesIJbtl4R7Bdu7paxKWXus/q1y/Ypr6FC4P5zz1X9eST3fCwYe5veffd8eNetMjNN26capcuLiGC6v/+56YPHuxqWaD6u99V/P2nT98z7uOOczvnBQvc3+SYY9y8v/pVMM/q1arr17saYHjZAw7YcxuA24HfcYcb9g8S/Ncrr7gk36mT6jvvBOUzZwaJBVxiDhs50iWV2N9No0buO4BL+L/5Tfnl/BgLC912bNHCJTRV9/9y6qmu7OGHq/79VMaSgkmK5593v5IOHdzRYmlpYkf8xcWqV1/tlj3iiOAfZMOG6seQnx8s7zcHxXuF5ea6st/+1h0x+/NMmuSmn3SS21GFbdpUfkcMqr//vVv+uedcc8rGjarnn++mtWypmpfnjloLCoJl/CO90lLXZPHqq67cb7aIZ/t2V/u44QYXg9+M4dc8fv5ztzOZOtV93syZ7v3xx92RcevW7vuAaypbs0a1W7f426l5c7dN/RrJ0UcHyfq661zSO/541TZtyh8p+zvToqI947/++vifNWeOqyE1aaL6k5+4nfKFF1a8HW69VTUrS/Wll1T//Ocg8Z96qpv+wQeqq1a54R07VP/6V7ctfBs2uL/TffcFMYwd62qNjz3malzPPhtMa9nSffd//ctt29/9zv12Fy9W/fRTN+2FF1yyKilxBzj+stu2lY991SrVjz92/zNjxrhmv/C2OOUU1SFD3HbdujXY5m3auOkrV6pec40bHjHCTQsnrI4dq9/kGWZJweyhtNRV43NzK5/vk0/cfCUl7ofs7zxee0313ntd1Tg/f8/l3npL9aKL3OccckjwTxf+x/jss/LLvPaaOyovKFAdNcrt3B57zLWBd+miOnCg+0cC1fPOqzghgOqBB7qj36OOUj3jDLeuzZtVP/oomOfvf3efe9557mgw/J07dnTzvPyyex8yJP72+dvf3PSLLipfHi85+du9WbMgSQ0Y4L7zHXe4HcO2beWTXZ8+brv44xU1j4Vddlmww//uO1f2m9+U3z5NmwY1jjFj3Hvnzu69Xz/3OXvt5Wpdd98dLPf6625H7e+87rtP9Yc/dL+PBx4IahxVvZ57zrX59+zpfl/du7vv3aGDqwX8+tduvnBfxE03Bb+96rrkErfdv/12z2nDhrn19u9fvXUWFVX8d44V3oYiLml8+GGQ5ED1iy/23E7+/0z79m6bd+4cNHVNmVK9eMMsKZg9rFqV2A/6hBPcPA8+6H7Mt9zijvCOPjpow/3tb/dc7tprg39+/2hn8WK3A/jhD13Zm28G84c7FZ98Mhg++WS3U4/9Z3njDdf0ceed5dvzK3pdc437nNJSF+/DDwdHuVdf7ToSfaecEuwsd+92O7v334+/fXbtUh09es/moKefdokxHr+T208O/lH8+++7I+Jw3Gec4ZpdEt35qLp26x//2CVAX2Ghq+nk5qr+4hcu2T3zTNBc0aqV64/o0sWN+x3cH3/sfivnnee2oX+0PHdu+e0+a5ZLFv37qw4f7pJyvL/D0KGqf/iDO7L3t4NfQ7n2Wtc0cvnlLikfdlj575Cf7/4WJSWJbYewjRtdc1g8q1a5g4+lS6u/3pdecq+qfP21qxUtXFi+037gwGAbPPRQ+W3VrZtLkBMnukR/ySXuf2j3btW77lJdsaL68fosKZg9vPVW+R3vG2+4polY/pke4HYC69ap3n9/UNaqlTvi7NJF9cgjVV980a3Prx107+7alMNVXT8hPfGE+2eM3Yl07Oh2MMOHa9mR1W23uR2tP8+CBcH6Djoo/g5owwa3EwLXJFCRm25yR9WqbscA8bdFMvk73VatXO0g3O5/4IFuJwmqN97o5q9OUqgOf5ted50b37Yt+Kxjj6182XCt4KijXO1j3To37Y9/jP83CTc3bd7stnujRq7pTVX1yiuDef/2t6R/3bTz8MPB9/VPBPBf4YSYbIkmhXr3OE5Tc19+GQzPmuVeAD//eXCVJgTn/u+3H4wfD506uQuzNm92V27ecAM8+6w7x/vll+HKK2H79mD5NWvcBTzZ2UHZft6TMt5/H6ZOdVd+HnKIu7L4wQfhm2/gjDPgpJOCc+Svuab8+ert2wfDPXvCkiVuXYWFcO21rrxdO7jnHhdfZVcX7723O+e9uNhd4Qxw3nkJbMRa6N/fndfevz+0auXifO01+N734Kyz4Mkn3Xz77+/en38eWrZMfhwXXQT5+e4dXCwPPeS25+23V77soEGwYIEb/ugj9106dXLj55/vrkOYNcut68Yb3d+4SZNg+b33hokT3W+ps3ej/IkT3bUcjRu7i78auksucddcvPRS8NvzHXpoamIqJ5HMkU4vqynU3E03uU7M1avLH50UFLiawLnnuqpqy5blz0ipjH9kH/t64IE9591nHzctKys4ulQNmm5ef901Z4SPkNevD8b9UylVXYcsuGaW776r/lG1f3rpd9+55iiR8uuPgt9JecMN8adPmhTUptJVuPkHgms2wi64wG3Pmp7GnCni9cVECaspmFgrV7oj9K5d3dFbcbErX7MGbrrJDXfpAgUFcMABia1zwAB3ZB/rsMP2LGvZ0tU0zj47OLoEGDnSlQ8f7mLq0QPuvttN69AhmK9Zs2B4xAj3fTp0cPeaOeus6t1eYO+93fuWLe5K5M6dy68/CkOGuKPyE0+MP33CBLeN0vk2CSNHwjPPBFdrx3u8ydlnu99XY9u7VKpnz6DWdfPNcPAeT7JPDfuzZZAvv3Q7+6ws6N7dVdkhaEYCmDvXvffqldg6BwyIX96v355lfrPUhAnly3/4Q/cCtyNZtSqYFm7WCjvhBPfyvfpqYvH6wklh9Wr3Dxq1nBzYtKninWXz5vCzn0UfR23st5+7CWCLFm48XlI4//zk3HCwoQv/j91zT/lmtlSyex9liPx8WLYsOBoJ7wRnznQ73zZtgiOXHj0SW++QIe7H7CeHW26BSy8Ndhphzz7r2o8rSiQVOf98OP746i1Tlb32cu9+TSHR71tbDeHouXnzoL8o3M9jqufII917r17pkxDAagoZ48UXoaTE3c0TyieF2bNdsmjaFD75xJV1jvu07D116eKan/bdF9avL98sFKumzSIvvFCz5Srj1xS+/dbdbK8uagoNSbt27sZ09nTcmhs50t2Ar1GaHZqnWTgmKi+84M4EOeQQN96nT/np/fsHR32tWkHr1omvu1Mn98OuLCGkGz8p+EnQkkL1tGvn3i0p1E7z5tH3ZVWXJYUM4J92edJJQdnVV8O//hWM9+gR/IPXp517TflJ4d133Xu8PhBTMUsKDZc1H2WARYvcU8EGDw7KsrPLn8ffvbtrX4fgmoKGzE8KH3/s+j8OPDC18dQ3bdu6d+tTaHgirSmIyHARWS4iK0VkQpzp+4vIOyLymYi8JyJdoownk3z5petDgOCMonBSgPJtmZlWU2jaNOgsHTDAnZFlEmc1hYYrsqQgIlnAZOAUoA9woYjEtGTzO+BpVT0UuAv4dVTxZJLPPnOnnvbuDXfdBWPHun9i/0rZeLp3D476MiEpQPB9411TYSrXqZM7g6s6fU+mfoiypjAYWKmqq1S1CJgGjIyZpw/wT2/43TjTTQ289JJ7X7MGfvUrN/z44xWf8w/uLKJMqimAu+XEXXfBuHGpjqT+uflm+Pe/K/9NmfopyqTQGVgbGs/zysIWAmd7w2cBrUVkn9gVicgYEckVkdz8/PxIgm0oVN2FXEcd5c5sKCpyncpnnln5co0bB0fOmdCnAO4+PrffXnfXKDQkbdqkzxW4JrlSffbRzcCxIvIpcCywDiiNnUlVp6jqIFUdlGONmJV65RX4/HN3AZnfhzBoUMXzv/GGe9A8uPl/8hN3uwljTGaK8uyjdUDX0HgXr6yMqv4Pr6YgIq2Ac1R1c4QxNVjPPQdffOEuUuvXz925dPVqd9ppZW3mp54aDGdnw/33Rx+rMSZ9RZkU5gG9RaQHLhmMAi4KzyAi7YGNqrobmAg8EWE8Ddoll7j35s3h+utdc9DVV7szkPr2TW1sxpj6I7LmI1UtAcYCs4ClwIuqukRE7hKRM7zZjgOWi8gXQEfgV1HFkyl27gzOIe/VC+67z063NMYkLtKL11R1JjAzpmxSaPhl4OUoY8gEpTG9MH5SMMaY6kp1R7NJgq+/Lj/epk1q4jDG1H+WFBqA1avLj1tNwRhTU5YUGgBLCsaYZLGk0AB89VX5cUsKxpiasqTQAGyOubLDkoIxpqYsKTQABQXlH+dnHc3GmJqypNAAFBQE9ytq1Sq9nvdqjKlf7CE7DUBBgbuFcZs2ditjY0ztWFJoAHbsgJYtXV+CJQVjTG1YUmgACgpcUigtdc1HxhhTU5YUGoCCAujcGSZMcI+ZNMaYmrKk0AD4NYWTTkp1JMaY+s7OPmoACgqgRYtUR2GMaQgsKTQAfkezMcbUliWFBsBvPjLGmNqypFDPlZRAUZElBWNMclhSqOcKCty7JQVjTDJYUqjn/KRgHc3GmGSINCmIyHARWS4iK0VkQpzp3UTkXRH5VEQ+E5FTo4ynIdqxw71bTcEYkwyRJQURyQImA6cAfYALRaRPzGy3AS+qan9gFPDHqOJpqKz5yBiTTFHWFAYDK1V1laoWAdOAkTHzKLCXN7w38L8I42mQLCkYY5IpyqTQGVgbGs/zysLuBC4RkTxgJjAu3opEZIyI5IpIbn5+fhSx1luWFIwxyZTqjuYLgamq2gU4FXhGRPaISVWnqOogVR2Uk5NT50GmM+toNsYkU5RJYR3QNTTexSsLuwp4EUBV5wLZQPsIY2pwrKPZGJNMUSaFeUBvEekhIk1xHckzYub5L3ACgIgciEsK1j5UDdZ8ZIxJpsiSgqqWAGOBWcBS3FlGS0TkLhE5w5vtJuAaEVkI/BUYraoaVUwNkSUFY0wyRXrrbFWdietADpdNCg1/DhwZZQwNnfUpGGOSKdUdzaaWCgogK8sermOMSQ5LCvWcf9tskVRHYoxpCCwp1HN222xjTDJZUqjnLCkYY5LJkkI9Z4/iNMYkkyWFes5qCsaYZLKkUM/Z85mNMclkSaGes5qCMSaZLCnUc5YUjDHJZEmhnrOOZmNMMkV6mwsTnU2boF07N2w1BWNMslhNoZ5asSIYtqRgjEkWSwr1VONQHc+SgjEmWSwp1FM7dwbDlhSMMcliSaGeCicF62g2xiSLJYV6ymoKxpgoWFKop8JJoaQkdXEYYxoWSwr1VDgpbNyYujiMMQ1LpElBRIaLyHIRWSkiE+JM/4OILPBeX4jI5ijjaUj8pDBkCFx2WWpjMcY0HJFdvCYiWcBkYBiQB8wTkRnec5kBUNUbQ/OPA/pHFU9D4yeFN9+ENm1SG4sxpuGIsqYwGFipqqtUtQiYBoysZP4Lgb9GGE+D4ieF5s1TG4cxpmGJMil0BtaGxvO8sj2IyP5AD+CfFUwfIyK5IpKbn5+f9EDro507oVEjaNo01ZEYYxqSdOloHgW8rKql8Saq6hRVHaSqg3Jycuo4tPS0c6erJYikOhJjTEMSZVJYB3QNjXfxyuIZhTUdVYufFIwxJpmiTArzgN4i0kNEmuJ2/DNiZxKRHwBtgbkRxtLg7NhhScEYk3xVJgURGScibau7YlUtAcYCs4ClwIuqukRE7hKRM0KzjgKmqapW9zMymdUUjDFRSOSU1I6400k/AZ4AZiW6A1fVmcDMmLJJMeN3JhaqCbOkYIyJQpU1BVW9DegNPA6MBlaIyD0i0ivi2EwlLCkYY6KQUJ+CVzNY771KcH0AL4vIbyOMzVTCkoIxJgqJ9CmMF5H5wG+BfwOHqOqPgIHAORHHZ+LYvds9m9mSgjEm2RLpU2gHnK2qX4ULVXW3iIyIJixTmWbN3J1Re/ZMdSTGmIYmkeajfwBl9+EUkb1EZAiAqi6NKjBTMf9W2VZTMMYkWyJJ4VFge2h8u1dmUqxZs1RHYIxpaBJJChI+BVVVdxPh3VVN4tZVdH24McbUUCJJYZWI/FhEmniv8cCqqAMzVVu5MtURGGMamkSSwrXAUNx9i/KAIcCYKIMyiTnmmFRHYIxpaKpsBlLVb3G3ojBpwG/Iu+oqmDw5tbEYYxqeKpOCiGQDVwEHAdl+uapeGWFcpgLFxe69Rw/raDbGJF8izUfPAPsCJwP/wt0Ce1uUQZn4du6Eb791w/ZwHWNMFBJJCgeo6u1Agao+BZyG61cwdez224N+hCZNUhuLMaZhSiQpeA0WbBaRg4G9gQ7RhWQqkpcHX3nXlVtSMMZEIZHrDaZ4z1O4DfeQnFbA7ZFGZeLaudPd9wis+cgYE41Kk4KINAK2quomYA5gd9tJoR07gmGrKRhjolBp85F39fLP6igWU4WdO4NhqykYY6KQSJ/CbBG5WUS6ikg7/xV5ZGYP4aRgNQVjTBQSSQoXANfjmo/me6/cRFYuIsNFZLmIrBSRCRXMc76IfC4iS0Tk+UQDz0SWFIwxUUvkiuYeNVmxiGQBk4FhuNtjzBORGar6eWie3sBE4EhV3SQidlZTJcJ9CtZ8ZIyJQiJXNF8Wr1xVn65i0cHASlVd5a1nGjAS+Dw0zzXAZK8j27+lhqmA1RSMMVFL5JTUw0LD2cAJwCdAVUmhM7A2NO7fTC/sewAi8m8gC7hTVd+MXZGIjMG7CV+3bt0SCLlhso5mY0zUEmk+GhceF5E2wLQkfn5v4Djc7TPmiMghqro5JoYpwBSAQYMGaexKMoXVFIwxUUukozlWAZBIP8M6oGtovItXFpYHzFDVYlVdDXyBSxImRnFx8BhOsKRgjIlGIn0KrwP+0XkjoA/wYgLrngf0FpEeuGQwCrgoZp7XgAuBJ0WkPa45yR7gE0e4lgDWfGSMiUYifQq/Cw2XAF+pal5VC6lqiYiMBWbh+gueUNUlInIXkKuqM7xpJ4nI50Ap8FNV3VDtb5EBYpOC1RSMMVFIJCn8F/haVQsBRKS5iHRX1TVVLaiqM4GZMWWTQsMK/MR7mUpYTcEYUxcS6VN4CdgdGi/1ykwdCl+jAFZTMMZEI5Gk0FhVi/wRb9iOU+uYNR8ZY+pCIkkhX0TO8EdEZCTwXXQhGYCf/hQef9zdKvvFF6GgoPx0az4yxkQhkT6Fa4HnROQRbzwPiHuVs0mel16CwYOhcWMYPRpGjCg/3WoKxpgoJHLx2pfA4SLSyhvfHnlUhsJCKCoKnsm8bFn56VZTMMZEocrmIxG5R0TaqOp2Vd0uIm1F5O66CC6TFRbCrl2upgCwbVv56VZTMMZEIZE+hVPCt53wbl53anQhGXAJYdeuYOe/dWv56VlZdR+TMabhSyQpZIlIM39ERJoDzSqZ39SSatB85NcUYm+GJ5Ka2IwxDVsiHc3PAe+IyJOAAKOBp6IMKtMVeScA79oFpaV7TremI2NMVBLpaP6NiCwETsTdA2kWsH/UgWWywkL3XlQUDPsaNbJOZmNMdBKpKQB8g0sI5wGrgVcii8iUJYJdu8o3G+21l6s5WE3BGBOVCpOCiHwPdwfTC3EXq71pL2a0AAAWMUlEQVQAiKoeX0exZaxwTSGcFHJyYNMmqykYY6JTWU1hGfA+MEJVVwKIyI11ElWGq6imkJPj7oFkNQVjTFQqO/vobOBr4F0R+bOInIDraDYRq6hPIScHmjWzpGCMiU6FSUFVX1PVUcAPgHeBG4AOIvKoiJxUVwFmospqCs2aWfORMSY6VV6noKoFqvq8qp6Oe6Tmp8AtkUeWwSrrU7CagjEmStV6RrOqblLVKap6QlQBGaspGGNSJ9FTUk0dCvcjhO951L49ZGe7K56NMSYK1aopVJeIDBeR5SKyUkQmxJk+WkTyRWSB97o6ynjqi3BS2LIlGG7ZEm65xb2MMSYKkdUURCQLmAwMwz2DYZ6IzFDVz2NmfUFVx0YVR30UTgqbNwfDzZrBaafVfTzGmMwRZU1hMLBSVVd5j/CcBoyM8PMajF27guFwTaF//7qPxRiTWaJMCp2BtaHxPK8s1jki8pmIvCwiXeOtSETGiEiuiOTm5+dHEWtaia0pXHyx60fo0iV1MRljMkOkfQoJeB3orqqHAm9Twd1XvTOeBqnqoJycnDoNMBXCSaG01HUuG2NMXYgyKawDwkf+XbyyMqq6QVX9xpK/AAMjjKfeiL0zavPmqYnDGJN5okwK84DeItJDRJoCo4AZ4RlEZL/Q6BnA0gjjqTcsKRhjUiWys49UtURExuKev5AFPKGqS0TkLiBXVWcAPxaRM4ASYCPuAT4Zz5KCMSZVIr14TVVnAjNjyiaFhicCE6OMoT6ypGCMSZVUdzSbOGKTgnU0G2PqiiWFNGQ1BWNMqlhSSEOFhSChJ1dkwFm4xpg0YUkhDRUWQuvWwXjneJf8GWNMBCwppKFt26Bdu2DckoIxpq5YUkhDmzbBvvsG4+FhY4yJkiWFNLRxY/lE0NieemGMqSOWFNJQbE3BGGPqiiWFNLNzp+to3m+/quc1xphks6SQRj74AEaMcMMdOqQ2FmNMZrLW6jRy9NHBcLt2MG4cnHlm6uIxxmQeSwoppgoPPghnn12+vF07eOih1MRkjMlc1nyUYqtXw403wv77ly9v2zY18RhjMpslhRSr6OmilhSMMalgSaGObN7s+gxWrChfvn59MHzQQcFw+IpmY4ypK5YU6sgbb7iziyZNKl8eTgqHHx4M77VX3cRljDFhlhSSpLQUzj8f5syJP71VK/deUFC+PJwUhgwJhhvZX8YYkwJ29lGSLFsGL73k+gKOOWbP6aWl7n3btvLl69dDixZw7bVw7rlwxBF7NjEZY0xdifR4VESGi8hyEVkpIhMqme8cEVERGRRlPMmycyc8+ijs2hWUffqpe58/P/4yfjLYvh2+/BJmeg8pXb8eevaE++93CeXgg+Gss6KL3RhjKhNZTUFEsoDJwDAgD5gnIjNU9fOY+VoD44GPoool2Z58Eq6/3h39jx3ryvyk8NlnLlk0a1Z+me3b3fu2bXDAAW5Y1SUFu6WFMSZdRFlTGAysVNVVqloETANGxpnvl8BvgMI405Ju9my46Sb4+9+huNiVffCBa7457TTX9PPww7B7t9th33OP2/mvXg1TpsDy5fDss265cePcEX5REXzkpbTiYnjiCde/UFISfG64phC2fr3d/M4Yk0ZUNZIXcC7wl9D4pcAjMfMMAF7xht8DBlWwrjFALpDbrVs3rY2TT1Z1x+iqjRur3nuvaqNGqq1bqx50kOqAAW7aAw+oHnecGz777GCZESPc+/DhQZm/zJlnqooE5V99FXzurbcG5f6rsFC1aVPVW26p1VcyxpgqAbmawL47Zee4iEgj4PfATVXNq6pTVHWQqg7KqeUDi4uK3Kmfkye7I/lXX3W1gnnzYPFiyM2FPn3gH/+A995zy7z6Khx2mGvm+d//XNno0a72APDJJ/DTn8Lzzwc3tAN3C2xfbA0B4OOPXTwDBtTqKxljTNJEmRTWAV1D4128Ml9r4GDgPRFZAxwOzIi6s7moyJ3tc9FFbtw/RbRFC/cuAkOHwqxZ5ZcbMcJdO+DP36QJdO8OgwZB8+YwcaJ7nxDqTt+4MRiOPesIgqQTvj7BGGNSKcqkMA/oLSI9RKQpMAqY4U9U1S2q2l5Vu6tqd+BD4AxVzY0wJoqL3Q69SRM37u/kmzYN5jniiGB46NDgvUmTPed/7LHgVFR/Pr/T2a8prF0L33zjbof94x/Dsce68vfec/0JXcOp0xhjUiiys49UtURExgKzgCzgCVVdIiJ34dq2ZlS+hmgUF7sdemxS8McBjjzSvY8eDZ07u9NMhwxxy8XOP3Dgnp/hJ4hNm9wDc7p1c+ODB7s7oj79NPzrX/Dhh3D88a52Yowx6SDSi9dUdSYwM6ZsUgXzHhdlLL6ioqprCt//Psyd63b4hYXuTKLWrd0yO3bsOX+scFKYPTso969qzs527zt2QPv2tf9OxhiTLBl3RbNfUxCBxo2DnXy4pgBBO3+TJnDoocGwf8Fa7PxhrVtDVpZLCtOnly8H1/fga9my5t/FGGOSLePusOPXFKD80X5lO3lfeP7KagoirrawaVP5K5z9moIlBWNMusq4pOB3NEPwnpWV2A3owomjqiTiJ4XwrTD8i9n85iOwpGCMSS8ZlxSKioKjfP89kVpCeP7Y4XjCScE/3XXDBvcerin4tQdjjEkHGZcU4tUUqtrB+6pbU9i40SWhnj1dWbykYDUFY0w6ycikUNOaQni+qhJJu3ZBTeF733Nl/vMSrPnIGJOuMu7so3BHc3VrCtXpmPabj4qK3HUKS5ZAr15umjUfGWPSVUYlBdX4zUc1qSlUtUzr1u4aCFV3G+0+fYJpVlMwxqSrjEoK/tk/sc1HNakpVLVMs2buwrd481qfgjEmXWVUn4L//IS6qCmEawOxD9wJj1vzkTEmnWRkUqiLjuZwUoidVySYbjUFY0w6yaikUFTk3pPR0dy4ioa3ymoKEDQhWVIwxqSTjEoKyaopNGlS9Z1NK6sphKdb85ExJp1kVFKobU2hOn0QidYU/KudjTEmHWRUUojtaK7pbS4SSSJV1RSaN3fzZGUl9tnGGFMXMiop+DWF2GRQk+ajqlRVU8jOtqYjY0z6yaikUNEpqdXtaE5W85F1Mhtj0k1GJoXadjQno/koO9uSgjEm/USaFERkuIgsF5GVIjIhzvRrRWSRiCwQkQ9EpE+89SRLXXY0h2sH8WoKhx0WPN3NGGPSRWS3uRCRLGAyMAzIA+aJyAxV/Tw02/Oq+pg3/xnA74HhUcWUTh3N99yT2GcaY0xdirKmMBhYqaqrVLUImAaMDM+gqltDoy0BjTCeCjuaU3FKqjHGpKMob4jXGVgbGs8DhsTOJCLXAz8BmgL/F29FIjIGGAPQrVu3GgeUTjUFY4xJRynvaFbVyaraC7gFuK2Ceaao6iBVHZSTk1Pjz4rtaE7lKanGGJOOoqwprAO6hsa7eGUVmQY8GmE8e3Q0V/fW2ck8+8gYE19xcTF5eXkU+veeN9WSnZ1Nly5daJLo0W6MKJPCPKC3iPTAJYNRwEXhGUSkt6qu8EZPA1YQodrWFKrT3FTV2UfGmPjy8vJo3bo13bt3R6q6yZgpR1XZsGEDeXl59OjRo0briCwpqGqJiIwFZgFZwBOqukRE7gJyVXUGMFZETgSKgU3A5VHFA8k7JTWR+bOy3PzFxZYUjKmOwsJCSwg1JCLss88+5Ofn13gdkT55TVVnAjNjyiaFhsdH+fmxktXRnOj82dnuM635yJjqsYRQc7XddinvaK5LdXnvIwj6FaymYIypLzIqKVRUU4ii+QiCZFDVA3mMMSZdZGRSqIuOZnA1hWbNqn4gjzEm85SUlKQ6hLgy6hi2Lk9JBZcUrD/BmJq74QZYsCC56+zXDx54oPJ5zjzzTNauXUthYSHjx49nzJgxvPnmm9x6662UlpbSvn173nnnHbZv3864cePIzc1FRLjjjjs455xzaNWqFdu3bwfg5Zdf5u9//ztTp05l9OjRZGdn8+mnn3LkkUcyatQoxo8fT2FhIc2bN+fJJ5/k+9//PqWlpdxyyy28+eabNGrUiGuuuYaDDjqIhx56iNdeew2At99+mz/+8Y9Mnz49qdsno5KCX1Pwm3Pqok/B+hOMqX+eeOIJ2rVrx86dOznssMMYOXIk11xzDXPmzKFHjx5s3LgRgF/+8pfsvffeLFq0CIBNmzZVue68vDz+85//kJWVxdatW3n//fdp3Lgxs2fP5tZbb+WVV15hypQprFmzhgULFtC4cWM2btxI27Ztue6668jPzycnJ4cnn3ySK6+8MunfPaOSQlFR+ecrV7emUN35raZgTO1UdUQflYceeqjsCHzt2rVMmTKFY445puzc/3bt2gEwe/Zspk2bVrZc27Ztq1z3eeedR5b3yMUtW7Zw+eWXs2LFCkSEYu/Idfbs2Vx77bU09o5g/c+79NJLefbZZ7niiiuYO3cuTz/9dJK+cSCjkkJxcfmjfKspGGNivffee8yePZu5c+fSokULjjvuOPr168eyZcsSXkf4tNDYK7Nbhh6kcvvtt3P88cczffp01qxZw3HHHVfpeq+44gpOP/10srOzOe+888qSRjJlTEfz55/Dc89BaWlQVtOO5urUFCwpGFO/bNmyhbZt29KiRQuWLVvGhx9+SGFhIXPmzGH16tUAZc1Hw4YNY/LkyWXL+s1HHTt2ZOnSpezevbvSNv8tW7bQuXNnAKZOnVpWPmzYMP70pz+VdUb7n9epUyc6derE3XffzRVXXJG8Lx2SMUnhtddg/Xrwtj9Qs+ajrCxo0SKx+Y89Fk48sXpxGmNSa/jw4ZSUlHDggQcyYcIEDj/8cHJycpgyZQpnn302ffv25YILLgDgtttuY9OmTRx88MH07duXd999F4B7772XESNGMHToUPbbb78KP+tnP/sZEydOpH///uXORrr66qvp1q0bhx56KH379uX5558vm3bxxRfTtWtXDjzwwEi+v6hG+giDpBs0aJDm5uZWe7nt22H1amjTBrp6t+krLITbb4c77oBWrRJbz9tvQ//+0L59tUMwxiRg6dKlke3wGoKxY8fSv39/rrrqqgrnibcNRWS+qg6qav0Z06fQqhUcckj5suxsuO++6q1n2LDkxWSMMdUxcOBAWrZsyf333x/ZZ2RMUjDGmPpu/vz5kX9GxvQpGGPqj/rWrJ1OarvtLCkYY9JKdnY2GzZssMRQA/7zFLLDT/mqJms+MsaklS5dupCXl1erZwJkMv/JazVlScEYk1aaNGlS46eGmdqz5iNjjDFlLCkYY4wpY0nBGGNMmXp3RbOI5ANf1XDx9sB3SQwnahZvdOpTrFC/4q1PsULmxLu/quZUNVO9Swq1ISK5iVzmnS4s3ujUp1ihfsVbn2IFizeWNR8ZY4wpY0nBGGNMmUxLClNSHUA1WbzRqU+xQv2Ktz7FChZvORnVp2CMMaZymVZTMMYYUwlLCsYYY8pkTFIQkeEislxEVorIhFTHE0tE1ojIIhFZICK5Xlk7EXlbRFZ4721TGN8TIvKtiCwOlcWNT5yHvG39mYgMSJN47xSRdd42XiAip4amTfTiXS4iJ9dxrF1F5F0R+VxElojIeK88LbdvJfGm3fYVkWwR+VhEFnqx/sIr7yEiH3kxvSAiTb3yZt74Sm9697qKtYp4p4rI6tC27eeVJ/+3oKoN/gVkAV8CPYGmwEKgT6rjiolxDdA+puy3wARveALwmxTGdwwwAFhcVXzAqcA/AAEOBz5Kk3jvBG6OM28f7zfRDOjh/Vay6jDW/YAB3nBr4AsvprTcvpXEm3bb19tGrbzhJsBH3jZ7ERjllT8G/Mgbvg54zBseBbxQx9u2oninAufGmT/pv4VMqSkMBlaq6ipVLQKmASNTHFMiRgJPecNPAWemKhBVnQNsjCmuKL6RwNPqfAi0EZGKn14egQrirchIYJqq7lLV1cBK3G+mTqjq16r6iTe8DVgKdCZNt28l8VYkZdvX20bbvdEm3kuB/wNe9spjt62/zV8GThARqYtYodJ4K5L030KmJIXOwNrQeB6V/4hTQYG3RGS+iIzxyjqq6tfe8HqgY2pCq1BF8aXz9h7rVbOfCDXHpU28XnNFf9wRYtpv35h4IQ23r4hkicgC4FvgbVxNZbOqlsSJpyxWb/oWYJ+6ijVevKrqb9tfedv2DyLSLDZeT623baYkhfrgKFUdAJwCXC8ix4Qnqqsrpu35w+ken+dRoBfQD/gaiO7p5zUgIq2AV4AbVHVreFo6bt848abl9lXVUlXtB3TB1VB+kOKQKhUbr4gcDEzExX0Y0A64JarPz5SksA7oGhrv4pWlDVVd571/C0zH/Xi/8auC3vu3qYswroriS8vtrarfeP9wu4E/EzRhpDxeEWmC28E+p6qvesVpu33jxZvO29eLbzPwLnAErpnFf8hYOJ6yWL3pewMb6jhUoFy8w70mO1XVXcCTRLhtMyUpzAN6e2ccNMV1IM1IcUxlRKSliLT2h4GTgMW4GC/3Zrsc+FtqIqxQRfHNAC7zzow4HNgSagZJmZi21rNw2xhcvKO8M096AL2Bj+swLgEeB5aq6u9Dk9Jy+1YUbzpuXxHJEZE23nBzYBiuD+Rd4Fxvttht62/zc4F/erW0OlFBvMtCBweC6/8Ib9vk/hai7k1Plxeul/4LXHviz1MdT0xsPXFnZywElvjx4doy3wFWALOBdimM8a+4JoFiXLvlVRXFhzsTYrK3rRcBg9Ik3me8eD7z/pn2C83/cy/e5cApdRzrUbimoc+ABd7r1HTdvpXEm3bbFzgU+NSLaTEwySvviUtMK4GXgGZeebY3vtKb3rOOt21F8f7T27aLgWcJzlBK+m/BbnNhjDGmTKY0HxljjEmAJQVjjDFlLCkYY4wpY0nBGGNMGUsKxhhjylhSMBlNREpDd55cIEm8g66IdJfQXVqNqQ8aVz2LMQ3aTnW3FDDGYDUFY+IS93yL34p7xsXHInKAV95dRP7p3ZjsHRHp5pV3FJHp3n3wF4rIUG9VWSLyZ+/e+G95V6kiIr1E5E3vBojvi8gPvPLzRGSxt445KfnyJqNZUjCZrnlM89EFoWlbVPUQ4BHgAa/sYeApVT0UeA54yCt/CPiXqvbFPcdhiVfeG5isqgcBm4FzvPIpwDhVHQjcDPzRK58EnOyt54xkf1ljqmJXNJuMJiLbVbVVnPI1wP+p6irv5m/rVXUfEfkOd/uGYq/8a1VtLyL5QBd1Nyzz19Edd+vj3t74Lbj74z8A5ONu+eBrpqoHishjuDuNvgi8qqopuRmbyVzWp2BMxbSC4erYFRouBZrjauib4/VlqOq1IjIEOA2YLyIDLTGYumTNR8ZU7ILQ+1xv+D+4u+wCXAy87w2/A/wIyh6SsndFK1X37IHVInKeN7+ISF9vuJeqfqSqk3C1ia4VrceYKFhSMJkutk/h3tC0tiLyGTAeuNErGwdc4ZVf6k3Dez9eRBYB83HPJa7MxcBVIuLfGdd/POx9Xuf2YlwCWljbL2hMdVifgjFxeH0Kg1T1u1THYkxdspqCMcaYMlZTMMYYU8ZqCsYYY8pYUjDGGFPGkoIxxpgylhSMMcaUsaRgjDGmzP8Dl6wtqbGwxNMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b401f8390>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy,color='b',label='accuracy')\n",
    "plt.title('Accuracy_Trend')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('behavior_image/accuracy_lstm_behavior_old_mean.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.059521\n",
      "\n",
      "Test Accuracy of left:100.0000(42/42)\n",
      "Test Accuracy of keep:93.8776(46/49)\n",
      "Test Accuracy of right:97.0588(33/34)\n",
      "Test Accuracy(Overall):96.8 (121/125)\n",
      "Test loss: 0.096 Test Accuracy:0.9683657884597778\n"
     ]
    }
   ],
   "source": [
    "net_test = LSTM(1,3,64,2)\n",
    "net_test.load_state_dict(torch.load('model/lstm_behavior_prediction_old_mean.pt'))\n",
    "if train_on_gpu:\n",
    "    net_test.cuda()\n",
    "    \n",
    "\n",
    "test(net_test,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
